[
  {
    "objectID": "ghg-center-at-ams-2024.html",
    "href": "ghg-center-at-ams-2024.html",
    "title": "The US GHG Center at American Meteorological Society Annual Meeting 2024",
    "section": "",
    "text": "Join members of the GHG Center team for several events at the 2024 AMS Annual Meeting at Baltimore, Maryland; January 28th - February 1st"
  },
  {
    "objectID": "ghg-center-at-ams-2024.html#short-course",
    "href": "ghg-center-at-ams-2024.html#short-course",
    "title": "The US GHG Center at American Meteorological Society Annual Meeting 2024",
    "section": "Short Course",
    "text": "Short Course\nAdvancing Open Science: An Interactive Workshop on Harnessing VEDA for Earth Science Research at the U.S. Greenhouse Gas Center\nüìÖ Jan 28, 2024, üï£ 8:00 AM - 3:45 PM EST, üìç Baltimore Convention Center\nLearn how to effectively analyze and visualize Earth science data in the cloud using open-source tools and datasets [Jan 28, room ]."
  },
  {
    "objectID": "ghg-center-at-ams-2024.html#town-hall",
    "href": "ghg-center-at-ams-2024.html#town-hall",
    "title": "The US GHG Center at American Meteorological Society Annual Meeting 2024",
    "section": "Town Hall",
    "text": "Town Hall\nU.S. Greenhouse Gas Center: Listening Session.\nüìÖ Jan 30, 2024, üï£ 12:25 PM - 1:15 PM EST, üìç Holiday 5, Hilton Baltimore Inner Harbor\nCome share your thoughts and see a demonstration of the US GHG Center. Upcoming developments and opportunities will be presented. [Jan 30, room Holiday 5 at Hilton Baltimore Inner Harbor]."
  },
  {
    "objectID": "ghg-center-at-ams-2024.html#presentations",
    "href": "ghg-center-at-ams-2024.html#presentations",
    "title": "The US GHG Center at American Meteorological Society Annual Meeting 2024",
    "section": "Presentations",
    "text": "Presentations\nMultiple presentations by GHG Center team members will occur throughout the week. Stop by to hear more from GHG Center team members!\n\n\n\n\n\n\n\n\n\nWhen\nRoom\nPresentation Title\n\n\n\n\nTues, Jan 30 4:45\nHoliday 5\nHilton Baltimore Inner Harbor\n8A.2 Stakeholder Engagement for the US Greenhouse Gas Center (Combley)\n\n\nMon, Jan 29 5:15\n336\nThe Baltimore Convention Center\nJ4B.4 Developing a Cross-Institutional Open-Source Cyberinfrastructure to Explore, Analyze, and Communicate Greenhouse Gas Data and Information (Chaudhary)\n\n\nTues, Jan 30 5:15\nBallroom II\nThe Baltimore Convention Center\nJ8A.4 PPAP‚Äôs and NIST‚Äôs Urban Greenhouse Gas Measurements Program (Whetstone)\n\n\nWed, Jan 31 5:30\nHoliday 5\nHilton Baltimore Inner Harbor\n12A.5 NIST‚Äôs Urban Greenhouse Gas Measurements Program and Interactions with NOAA‚Äôs Air Resources Laboratory (Whetstone)\n\n\nMon, Jan 29 11:30\n321/322\nThe Baltimore Convention Center\n2B.4 Methane and Carbon Dioxide Point Source Measurements Across Six Continents from the EMIT Imaging Spectrometer on the International Space Station - and Contributions to the U.S. Greenhouse Gas Center (Green)\n\n\nMon, Jan 29 5:30\n321/322\nThe Baltimore Convention Center\n4B.5 Detectability of Anthropogenic Impacts on Terrestrial Carbon Storage through Space Based Greenhouse Gas Observations (Weir)\n\n\nThur, Feb 1 2:30\nHoliday 4\nHilton Baltimore Inner Harbor\nJ15.4 NOAA Carbon Monitoring, Research and Innovation: Long-Standing Foundation to Support Climate Mitigation (Grubi≈°iƒá)"
  },
  {
    "objectID": "intro-us-ghg-center/index.html",
    "href": "intro-us-ghg-center/index.html",
    "title": "Introduction to US GHG Center",
    "section": "",
    "text": "Introduction to US GHG Center"
  },
  {
    "objectID": "interactive-session-1-epa-gridded-methane-emissions/index.html",
    "href": "interactive-session-1-epa-gridded-methane-emissions/index.html",
    "title": "EPA Gridded Methane Emissions Inventory",
    "section": "",
    "text": "EPA Gridded Methane Emissions Inventory"
  },
  {
    "objectID": "speakers.html",
    "href": "speakers.html",
    "title": "Speakers",
    "section": "",
    "text": "Argie Kavvada (HQ)\nShanna Combley (HQ)\nLesley Ott (GSFC)\nEmily Bell (GSFC)\n\n\n\n\n\nErin McDuffie\n\n\n\n\nTBD\n\n\n\nTBD\n\n\n\n\nKevin Bowman\nRob Green\n\n\n\n\n\nDeborah Smith\nSlesa Adhikari\nSiddharth Chaudhary"
  },
  {
    "objectID": "speakers.html#national-aeronautics-and-space-administration-nasa",
    "href": "speakers.html#national-aeronautics-and-space-administration-nasa",
    "title": "Speakers",
    "section": "",
    "text": "Argie Kavvada (HQ)\nShanna Combley (HQ)\nLesley Ott (GSFC)\nEmily Bell (GSFC)"
  },
  {
    "objectID": "speakers.html#environmental-protection-agency-epa",
    "href": "speakers.html#environmental-protection-agency-epa",
    "title": "Speakers",
    "section": "",
    "text": "Erin McDuffie"
  },
  {
    "objectID": "speakers.html#national-institute-for-standards-and-technology-nist",
    "href": "speakers.html#national-institute-for-standards-and-technology-nist",
    "title": "Speakers",
    "section": "",
    "text": "TBD"
  },
  {
    "objectID": "speakers.html#national-oceanic-and-atmospheric-administration-noaa",
    "href": "speakers.html#national-oceanic-and-atmospheric-administration-noaa",
    "title": "Speakers",
    "section": "",
    "text": "TBD"
  },
  {
    "objectID": "speakers.html#jet-propulsion-laboratory-jpl",
    "href": "speakers.html#jet-propulsion-laboratory-jpl",
    "title": "Speakers",
    "section": "",
    "text": "Kevin Bowman\nRob Green"
  },
  {
    "objectID": "speakers.html#university-of-alabama-in-huntsville-uah",
    "href": "speakers.html#university-of-alabama-in-huntsville-uah",
    "title": "Speakers",
    "section": "",
    "text": "Deborah Smith\nSlesa Adhikari\nSiddharth Chaudhary"
  },
  {
    "objectID": "interactive-session-2-anthropogenic-ghg-emissions/draft-sid.html",
    "href": "interactive-session-2-anthropogenic-ghg-emissions/draft-sid.html",
    "title": "Flow of Workshop",
    "section": "",
    "text": "Reading data\n\nRead LPJ dataset from STAC\nRead subset of Merra-2 (few variables) data using credentials\nCreating different region of interest\n\nStatistical Analysis\n\nSelect the region and create time series of total emission in the region Note we will have line chart for two different years to show inter annual variability\nCreate dual folium map to show visual comparision\nPlot monthly mean and climate mean using merra-2 data for same region of interest\nPlot time series for the following data and time period to interpret the results:\n\n2020, 2021 - LPJ monthly emissions\n2020, 2021 - Merra 2 T2M monthly anomaly\n2020, 2021 - Total precipitation rate\nDatasets to be used 1. Monthly LPJ Wetland CH4 Emissions 2. Monthly MERRA-2 Precipitation RateDataset: MERRA2_400.tavgM_2d_flx_Nx Variable: ‚ÄòPRECTOT‚Äô https://disc.gsfc.nasa.gov/datasets/M2TMNXFLX_5.12.4/summary\nUse case to be discussed: 1. Midwest floods in 2019 2. Pick events of interest"
  },
  {
    "objectID": "interactive-session-2-anthropogenic-ghg-emissions/draft-sid.html#defining-region-of-interest",
    "href": "interactive-session-2-anthropogenic-ghg-emissions/draft-sid.html#defining-region-of-interest",
    "title": "Flow of Workshop",
    "section": "Defining region of interest",
    "text": "Defining region of interest\n\nboundaries={\n    'Global':[-180,180,-90,90],\n    'Louisiana': [-95.9,-87.50,28.7,33.5],\n    'CONUS':[-127.08,-63.87,23.55,49.19],   #   conus\n    'Florida':[-84.07,-79.14,24.85,30.5],\n    'Northeast':[-74.88,-69.81,40.48,42.88]\n}\n\n\nReading MERRA-2 Data\n\nparams={\n    'MERRA-2 T2M':\n        {'var':'T2M',\n        'cmap':'Spectral_r',\n        'dir':merra_t2m_dir,\n        'nickname':'merra2_t2m',\n        'climdir':merra_t2m_clim_dir,\n        'climvar':'T2MMEAN'},\n    'MERRA-2 Surface Soil Moisture':\n        {'var':'GWETTOP',\n        'cmap':'Blues',\n        'dir':merra_soil_moisture_dir,\n        'nickname':'merra2_sm',\n        'climdir':merra_soil_moisture_clim_dir,\n        'climvar':'GWETTOP'},\n    'MERRA-2 Precipitation Rate':\n        {'var':'PRECTOT',\n        'cmap':'Spectral_r',\n        'dir':merra_precip_rate_dir,\n        'nickname':'merra2_pr',\n        'climdir':merra_precip_rate_clim_dir,\n        'climvar':'PRECTOT'}\n}"
  },
  {
    "objectID": "interactive-session-2-anthropogenic-ghg-emissions/draft-sid.html#mothly-time-series",
    "href": "interactive-session-2-anthropogenic-ghg-emissions/draft-sid.html#mothly-time-series",
    "title": "Flow of Workshop",
    "section": "Mothly Time Series",
    "text": "Mothly Time Series\n\ndef get_merra2_timeseries(year,focus,p,anomaly):\n    files = glob.glob(params[p]['dir']+'%s/*.nc4'%(year))\n    if anomaly:\n        try:\n            clim_files = glob.glob(params[p]['climdir']+'*.nc4')\n        except:\n            print('Climatological mean files (climdir) not found for specified parameter.')\n            breakpoint()\n    month_labels = []\n    box_totals = []\n    month_field = []\n    dt = []\n    for i,f in enumerate(files):\n        data = nc.Dataset(f)\n        \n        #   Get bounding box\n        wlat = np.logical_and(\n            data['lat'][:] &lt; boundaries[focus][3],\n            data['lat'][:] &gt; boundaries[focus][2]\n        )\n        wlon = np.logical_and(\n            data['lon'][:] &lt; boundaries[focus][1],\n            data['lon'][:] &gt; boundaries[focus][0]\n        )\n\n        datestamp = f.split('.')[-2]\n        month = int(datestamp[-2::])\n\n        dt.append(datetime(year,month,1))\n        month_labels.append(datetime(year,month,1).strftime('%B'))\n\n        if anomaly:\n            #   Make sure you read the climatology for the right month (whichfile)\n            whichfile = [datetime(2020,month,1).strftime('%y%m') in f for f in clim_files]\n            climdata = nc.Dataset(np.array(clim_files)[whichfile][0])\n            \n            #   Calculate sum (emissions) or mean (met params) over your bounding box\n            if 'LPJ' in p:\n                clim_box_total = np.nansum(climdata[params[p]['climvar']][0,wlat,wlon])\n                now_box_total = np.nansum(data[params[p]['var']][0,wlat,wlon])\n            elif 'MERRA' in p:\n                clim_box_total = np.nanmean(climdata[params[p]['climvar']][0,wlat,wlon])\n                now_box_total = np.nanmean(data[params[p]['var']][0,wlat,wlon])\n\n            #   Replace fill values with NaN \n            #   Otherwise differencing might give wild results? (Just be safe)\n            wfillclim = np.where(climdata[params[p]['climvar']][0,:,:] == climdata[params[p]['climvar']]._FillValue)\n            climfield = climdata[params[p]['climvar']][0,:,:]\n            climfield[wfillclim] = np.nan\n            wfillnow = np.where(data[params[p]['var']][0,:,:] == data[params[p]['var']]._FillValue)\n            nowfield = data[params[p]['var']][0,:,:]\n            nowfield[wfillnow] = np.nan\n\n            #   And finally, difference current month and long-term mean \n            box_totals.append(now_box_total - clim_box_total)\n            month_field.append(nowfield - climfield)\n            climdata.close()\n        else:\n            if 'LPJ' in p:\n                box_totals.append(np.nansum(data[params[p]['var']][0,wlat,wlon]))\n            elif 'MERRA' in p:\n                box_totals.append(np.nanmean(data[params[p]['var']][0,wlat,wlon]))\n            #   Replace fill values with NaN (otherwise maps are hard to read) \n            month_field.append(data[params[p]['var']][0,:,:])\n            wfill = np.where(month_field[-1] == data[params[p]['var']]._FillValue)\n            month_field[-1][wfill] = np.nan\n            #breakpoint()\n\n    #   Sort in case months are out of order\n    dti = np.argsort(dt)\n    month_labels = np.array(month_labels)[dti]\n    box_totals = np.array(box_totals)[dti]\n    month_field = np.array(month_field)[dti]\n\n    print('mean ',np.nanmean(month_field))\n    print('std ',np.nanstd(month_field))\n\n    data_return = {\n        'month_labels':month_labels,\n        'box_totals':box_totals,\n        'month_fields':month_field,\n        'units':data[params[p]['var']].units,\n        'lat':data['lat'][:],\n        'lon':data['lon'][:]\n    }\n    data.close()\n    return data_return \n\n\ndef monthly_timeseries(year,focus,param,anomaly):\n    labels = []\n    cmap = plt.get_cmap('gnuplot') \n    colors = cmap(np.linspace(0,1,len(param)))\n    for i,p in enumerate(param):\n    #   Don't pass multiple [param] at a time.\n        if 'LPJ' in p:\n            ts = get_lpj_timeseries(year,focus,p)\n        elif 'MERRA' in p:\n            ts = get_merra2_timeseries(year,focus,p,anomaly)\n            \n        if i == 0:\n            fig = plt.figure(figsize=(6,3))\n            ax = fig.add_subplot(111)\n\n        #breakpoint()\n        try:\n            ax.plot(\n                list(range(0,12)),\n                ts['box_totals'],\n                linestyle='-',\n                linewidth=2,\n                color=colors[i],\n                markersize=4,\n                marker='o',\n                label=p\n            )\n        except ValueError:\n            print('Double check that you have all twelve months of MERRA-2 data downloaded!')\n            print(params[p]['dir'])\n            breakpoint()\n\n        #   Construct plot title\n        title = '%s\\n%s Mean Monthly %s'%(focus,year,p)\n        if anomaly:\n           title+=' Anomaly' \n        if 'LPJ' in p:\n            title = title.replace('Mean','Total')\n        plt.title(title)\n        \n        plt.xticks(list(range(0,12)))\n        ax.set_xticklabels(ts['month_labels'],rotation=40,ha='right')\n\n\n        if p == param[-1]:\n            if i &gt; 0:\n                ax.legend(loc='best')\n                nickname = '_'.join(params[p]['nickname'] for p in params)\n                savename = '%s/box_summed_%s_%s_%s.png'% \\\n                    (savedir,nickname,year,focus)\n            else:\n                nickname = params[p]['nickname']\n                savename = '%s/%s/%s/box_summed_%s_%s_%s.png'% \\\n                    (savedir,nickname,focus,nickname,year,focus)\n            if anomaly:\n                ax.plot(list(range(-1,13)),np.zeros(14),linewidth=0.4)\n                savename = savename.replace('.png','_Anomaly.png')\n            ax.set_xlim(-1,12)\n            ax.set_ylim(-4e-5,4e-5)     #   manual per parameter\n            print('Saving to '+savename)\n            plt.figure(1).savefig(savename,dpi=300,bbox_inches='tight')\n\n    return ts"
  },
  {
    "objectID": "intro-stac/index.html",
    "href": "intro-stac/index.html",
    "title": "Spatio-Temporal Asset Catalog",
    "section": "",
    "text": "Spatio-Temporal Asset Catalog"
  },
  {
    "objectID": "prerequisites.html",
    "href": "prerequisites.html",
    "title": "Prerequisites",
    "section": "",
    "text": "Participants are expected to have a basic knowledge of the python programming language.\nParticipants MUST obtain the following to be able to follow along the workshop:\n\nUS GHG Center JupyterHub Access\nEarthdata credentials\n\n\n\nüö® Please make sure you have both of the accesses before you come to the workshop on Sunday.\n\n\n\nThe US GHG Center notebook environment is available to authorized users on an as-need basis. You can request access by using our Hub Access Request form.\n\nMake sure you have a GitHub Account. Take note of your GitHub username.\nFill out the request form and provide needed information. Make sure to use your organization/univerity email and use ‚ÄúAMS Workshop 2024‚Äù as the reason.\nWatch your email for notification of authorization and the invite to join the US GHG Center Hub Access GitHub Team.\nOnce you accept the invitation, you can go to hub.ghg.center and login using your GitHub credentials.\n\n\n\n\nFollow the tutorial on this link to register for Earthdata login: https://www.earthdata.nasa.gov/eosdis/science-system-description/eosdis-components/earthdata-login.\nMake sure to note your username and password."
  },
  {
    "objectID": "prerequisites.html#to-get-us-ghg-center-jupyterhub-access",
    "href": "prerequisites.html#to-get-us-ghg-center-jupyterhub-access",
    "title": "Prerequisites",
    "section": "",
    "text": "The US GHG Center notebook environment is available to authorized users on an as-need basis. You can request access by using our Hub Access Request form.\n\nMake sure you have a GitHub Account. Take note of your GitHub username.\nFill out the request form and provide needed information. Make sure to use your organization/univerity email and use ‚ÄúAMS Workshop 2024‚Äù as the reason.\nWatch your email for notification of authorization and the invite to join the US GHG Center Hub Access GitHub Team.\nOnce you accept the invitation, you can go to hub.ghg.center and login using your GitHub credentials."
  },
  {
    "objectID": "prerequisites.html#to-obtain-earthdata-credentials",
    "href": "prerequisites.html#to-obtain-earthdata-credentials",
    "title": "Prerequisites",
    "section": "",
    "text": "Follow the tutorial on this link to register for Earthdata login: https://www.earthdata.nasa.gov/eosdis/science-system-description/eosdis-components/earthdata-login.\nMake sure to note your username and password."
  },
  {
    "objectID": "agenda.html",
    "href": "agenda.html",
    "title": "Workshop Agenda",
    "section": "",
    "text": "Workshop Agenda\nThe full-day workshop will be divided into the following sections:\n\n\n\n\n\n\n\n\n8:00 - 8:15\nWelcome\n\nWelcome message\nWorkshop Introduction\nTeam Introduction\nIcebreaker\n\n\n\n8:15 - 8:45\nOverview of the U.S. Greenhouse Gas Center and the Science\n\nWhat is the US GHG Center?\nRole of Methane and Carbon Dioxide in Climate Change\nWhat is included in the Center and why these datasets\nIntroduction to the science use cases / demonstration areas that will be explored during the workshop\n\n\n\n8:45 - 10:00\nIntroduction to the GHG Center Data Catalog\n\nIntro to the VEDA project and its relevance to Earth Science research and the US GHG Center\nWhat is a STAC catalog?\nHands-on exercise: searching and accessing cloud-optimized datasets using the STAC catalog\n\nIntro to JupyterHub and Jupyter Notebooks\n\nAccess to the JupyterHub environment\nCreating and running a Jupyter Notebook in the hub\n\nUsing the pystac client library to read the US GHG STAC catalog\n\nList all available datasets\nSpatial and temporal search\nAccess assets and visualize them\n\nAccessing the US GHG STAC catalog using QGIS on the browser\n\nEstablishing connection to the US GHG STAC catalog using the qgis-stac-plugin in QGIS in the GHG Center JupyterHub environment\nAdding a dataset/asset from the catalog as layer in QGIS\n\n\n\n\n\n10:00 - 10:15\nBREAK\n\n\n10:15 - 11:15\nInteractive Session 1: EPA Gridded Methane Emissions Inventory\n\nBackground and gridding methods overview/ example\nImproving access and latency of human anthropogenic emissions\nHands-on exercise\n\n\n\n11:15 - 12:15\nInteractive Session 2: Complementing anthropogenic GHG emissions with natural GHG emissions and fluxes\n\nDescription of data sets and analysis available via the U.S. GHG Center (e.g., gridded wetland emissions and ecosystem exchange estimates)\nHands-on exercise: Exploring annual U.S. wetland methane emissions and their - meteorological influences.\n\n\n\n12:15 - 1:30\nLUNCH BREAK\n\n\n1:30 - 2:45\nIdentifying and quantifying emissions from large point source methane emission events leveraging aircraft and satellite data\n\nDescription of data sets and analysis available via the U.S. GHG Center (e.g., EMIT methane enhancements; plans for emission rates, CO2, etc.)\nHands-on exercise: Locating enhancement, understanding temporal relevance, exploring site with multiple observations.\n\n\n\n2:45 - 3:15\nOpen Science in Action: Intro to GitHub & Communicating Science Discoveries via Web Dashboard\n\nHow do VEDA, GitHub, and JupyterHub interoperate and why is this important?\nIntroduction to web dashboards for science communication\n\nHands-on exercise: creating a web dashboard to communicate science discoveries using the platform\n\n\n\n\n3:15 - 3:30\nClosing Remarks\n\nFuture Developments and Community Contributions\nEngaging with the U.S. Greenhouse Gas Center\n\n\n\n\nThroughout the workshop, facilitators will be available to provide support and guidance, ensuring participants are able to actively explore the workshop topics and apply their knowledge and skills to their own research projects."
  },
  {
    "objectID": "open-science-in-action/index.html",
    "href": "open-science-in-action/index.html",
    "title": "Open Science in Action: Intro to GitHub & Communicating Science Discoveries via Web Dashboard",
    "section": "",
    "text": "Open Science in Action: Intro to GitHub & Communicating Science Discoveries via Web Dashboard"
  },
  {
    "objectID": "chapters.html",
    "href": "chapters.html",
    "title": "Chapters",
    "section": "",
    "text": "The flow of the workshop\n\n\n\nIntro to the US GHG Center\nThe US GHG Center Data Catalog (STAC)\nThe US GHG Center JupyterHub environment\n\n\n\n\n\nEPA Gridded Methane Emissions Inventory\nComplementing anthropogenic GHG emissions with natural GHG emissions and fluxes\nIdentifying and quantifying emissions from large point source methane emission events leveraging aircraft and satellite data\n\n\n\n\n\nIntro to GitHub & Communicating Science Discoveries via Web Dashboard\n\n\n‚ÑπÔ∏è Content for each chapter will be added as they are prepared, please check back."
  },
  {
    "objectID": "chapters.html#introduction",
    "href": "chapters.html#introduction",
    "title": "Chapters",
    "section": "",
    "text": "Intro to the US GHG Center\nThe US GHG Center Data Catalog (STAC)\nThe US GHG Center JupyterHub environment"
  },
  {
    "objectID": "chapters.html#science-use-cases",
    "href": "chapters.html#science-use-cases",
    "title": "Chapters",
    "section": "",
    "text": "EPA Gridded Methane Emissions Inventory\nComplementing anthropogenic GHG emissions with natural GHG emissions and fluxes\nIdentifying and quantifying emissions from large point source methane emission events leveraging aircraft and satellite data"
  },
  {
    "objectID": "chapters.html#open-science-in-action",
    "href": "chapters.html#open-science-in-action",
    "title": "Chapters",
    "section": "",
    "text": "Intro to GitHub & Communicating Science Discoveries via Web Dashboard\n\n\n‚ÑπÔ∏è Content for each chapter will be added as they are prepared, please check back."
  },
  {
    "objectID": "interactive-session-2-anthropogenic-ghg-emissions/lpjwsl-wetlandch4-grid-v1_User_Notebook.html",
    "href": "interactive-session-2-anthropogenic-ghg-emissions/lpjwsl-wetlandch4-grid-v1_User_Notebook.html",
    "title": "Wetland Methane Emissions, LPJ-wsl Model",
    "section": "",
    "text": "Identify available dates and temporal frequency of observations for the given collection using the GHGC API /stac endpoint. The collection processed in this notebook is the Wetland Methane Emissions, LPJ-wsl Model data product.\nPass the STAC item into the raster API /stac/tilejson.jsonendpoint.\nUsing plugins from folium to visualize two tiles (side-by-side), allowing time point comparison.\nAfter the visualization, perform zonal statistics for a given polygon.\nRead monthly MERRA-2 data for different variables (precipitation rate, surface soil moisture)\nPlot monthly time series for LPJ-wetland emission and different MERRA-2 dataset and analyse them."
  },
  {
    "objectID": "interactive-session-2-anthropogenic-ghg-emissions/lpjwsl-wetlandch4-grid-v1_User_Notebook.html#approach",
    "href": "interactive-session-2-anthropogenic-ghg-emissions/lpjwsl-wetlandch4-grid-v1_User_Notebook.html#approach",
    "title": "Wetland Methane Emissions, LPJ-wsl Model",
    "section": "",
    "text": "Identify available dates and temporal frequency of observations for the given collection using the GHGC API /stac endpoint. The collection processed in this notebook is the Wetland Methane Emissions, LPJ-wsl Model data product.\nPass the STAC item into the raster API /stac/tilejson.jsonendpoint.\nUsing plugins from folium to visualize two tiles (side-by-side), allowing time point comparison.\nAfter the visualization, perform zonal statistics for a given polygon.\nRead monthly MERRA-2 data for different variables (precipitation rate, surface soil moisture)\nPlot monthly time series for LPJ-wetland emission and different MERRA-2 dataset and analyse them."
  },
  {
    "objectID": "interactive-session-2-anthropogenic-ghg-emissions/lpjwsl-wetlandch4-grid-v1_User_Notebook.html#about-the-data",
    "href": "interactive-session-2-anthropogenic-ghg-emissions/lpjwsl-wetlandch4-grid-v1_User_Notebook.html#about-the-data",
    "title": "Wetland Methane Emissions, LPJ-wsl Model",
    "section": "About the Data",
    "text": "About the Data\nMethane (CH‚ÇÑ) emissions from wetlands are estimated to be the largest natural source of methane in the global CH‚ÇÑ budget, contributing to roughly one third of the total of natural and anthropogenic emissions. Wetland CH‚ÇÑ is produced by microbes breaking down organic matter in the oxygen deprived environment of inundated soils. Due to limited data availability, the details of the role of wetland CH‚ÇÑ emissions has thus far been underrepresented. Using the Wald Schnee und Landschaft version (LPJ-wsl) of the Lund-Potsdam-Jena Dynamic Global Vegetation Model (LPJ-DGVM) global CH‚ÇÑ emissions from wetlands are estimated at 0.5 x 0.5 degree resolution by simulating wetland extent and using characteristics of these inundated areas, such as soil moisture, temperature, and carbon content, to estimate CH‚ÇÑ quantities emitted into the atmosphere. Highlighted areas displayed in this dataset show concentrated methane sources from tropical and high latitude ecosystems. The LPJ-wsl Wetland Methane Emissions data product presented here consists of global daily and monthly model estimates of terrestrial wetland CH‚ÇÑ emissions from 1980 - 2021. These data are regularly used in conjunction with NASA‚Äôs Goddard Earth Observing System (GEOS) model to simulate the impact of wetlands and other methane sources on atmospheric methane concentrations, to compare against satellite and airborne data, and to improve understanding and prediction of wetland emissions."
  },
  {
    "objectID": "interactive-session-2-anthropogenic-ghg-emissions/lpjwsl-wetlandch4-grid-v1_User_Notebook.html#flow-of-workshop",
    "href": "interactive-session-2-anthropogenic-ghg-emissions/lpjwsl-wetlandch4-grid-v1_User_Notebook.html#flow-of-workshop",
    "title": "Wetland Methane Emissions, LPJ-wsl Model",
    "section": "Flow of Workshop",
    "text": "Flow of Workshop\n\nReading data\n\nRead LPJ dataset from STAC\nRead subset of Merra-2 (few variables) data using credentials\nCreating different region of interest\n\nStatistical Analysis\n\nSelect the region and create time series of total emission in the region Note we will have line chart for two different years to show inter annual variability\nCreate dual folium map to show visual comparision\nPlot monthly mean and climate mean using merra-2 data for same region of interest\nPlot time series for the following data and time period to interpret the results:\n\n2020, 2021 - LPJ monthly emissions\n2020, 2021 - Merra 2 T2M monthly anomaly\n2020, 2021 - Total precipitation rate\n\n\n\nDatasets to be used 1. Monthly LPJ Wetland CH4 Emissions 2. Monthly MERRA-2 Precipitation RateDataset: MERRA2_400.tavgM_2d_flx_Nx Variable: ‚ÄòPRECTOT‚Äô https://disc.gsfc.nasa.gov/datasets/M2TMNXFLX_5.12.4/summary\n\nMonthly MERRA-2 Surface Soil MoistureDataset: MERRA2_400.tavgM_2d_lnd_Nx Variable: ‚ÄòSFMC‚Äô Long-term mean variable: ‚ÄòGWETTOP‚Äô https://disc.gsfc.nasa.gov/datasets/M2TMNXLND_5.12.4/summary\nMonthly MERRA-2 T2MDataset: MERRA2_400.instM_2d_asm_Nx Variable: ‚ÄòT2M‚Äô https://disc.gsfc.nasa.gov/datasets/M2IMNXASM_5.12.4/summary\nMERRA-2 Long-Term MeansMERRA2.tavgC_2d_ltm_Nx https://disc.gsfc.nasa.gov/datasets/M2TCNXLTM_1/summary\n\nUse case to be discussed: 1. Midwest floods in 2019 2. Pick events of interest"
  },
  {
    "objectID": "interactive-session-2-anthropogenic-ghg-emissions/lpjwsl-wetlandch4-grid-v1_User_Notebook.html#querying-the-stac-api",
    "href": "interactive-session-2-anthropogenic-ghg-emissions/lpjwsl-wetlandch4-grid-v1_User_Notebook.html#querying-the-stac-api",
    "title": "Wetland Methane Emissions, LPJ-wsl Model",
    "section": "Querying the STAC API",
    "text": "Querying the STAC API\n\nimport requests\nimport folium\nimport folium.plugins\nfrom folium import Map, TileLayer \nfrom pystac_client import Client \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport branca.colormap as cm\nimport geopandas\nfrom pyproj import Geod\nfrom shapely import wkt\nimport seaborn as sns\nimport glob\nimport numpy as np\nfrom datetime import datetime\nimport netCDF4 as nc\n\n\n# Provide STAC and RASTER API endpoints\nSTAC_API_URL = \"http://ghg.center/api/stac\"\nRASTER_API_URL = \"https://ghg.center/api/raster\"\n\n# Please use the collection name similar to the one used in STAC collection.\n\n# Name of the collection for wetland methane monthly emissions. \ncollection_name = \"lpjwsl-wetlandch4-monthgrid-v1\"\n\n\n# Fetching the collection from STAC collections using appropriate endpoint.\ncollection = requests.get(f\"{STAC_API_URL}/collections/{collection_name}\").json()\ncollection\n\n{'id': 'lpjwsl-wetlandch4-monthgrid-v1',\n 'type': 'Collection',\n 'links': [{'rel': 'items',\n   'type': 'application/geo+json',\n   'href': 'https://ghg.center/api/stac/collections/lpjwsl-wetlandch4-monthgrid-v1/items'},\n  {'rel': 'parent',\n   'type': 'application/json',\n   'href': 'https://ghg.center/api/stac/'},\n  {'rel': 'root',\n   'type': 'application/json',\n   'href': 'https://ghg.center/api/stac/'},\n  {'rel': 'self',\n   'type': 'application/json',\n   'href': 'https://ghg.center/api/stac/collections/lpjwsl-wetlandch4-monthgrid-v1'}],\n 'title': 'Wetland Methane Emissions, LPJ-wsl Model (Monthly)',\n 'assets': None,\n 'extent': {'spatial': {'bbox': [[-180, -90, 180, 90]]},\n  'temporal': {'interval': [['1980-01-01T00:00:00+00:00',\n     '2021-12-01T00:00:00+00:00']]}},\n 'license': 'CC-BY-4.0',\n 'keywords': None,\n 'providers': None,\n 'summaries': {'datetime': ['1980-01-01T00:00:00Z', '2021-12-01T00:00:00Z']},\n 'description': 'Wetland methane emissions produced by the Lund‚ÄìPotsdam‚ÄìJena Dynamic Global Vegetation Model (LPJ-DGVM) Wald Schnee und Landscaft version (LPJ-wsl). LPJ-wsl is a prognostic model used to simulate future changes in wetland emissions and independently verified with remote sensing data products. The LPJ-wsl model is regularly used in conjunction with NASA‚Äôs GEOS model to simulate the impact of wetlands and other methane sources on atmospheric methane concentrations.',\n 'item_assets': {'ch4-wetlands-emissions': {'type': 'image/tiff; application=geotiff; profile=cloud-optimized',\n   'roles': ['data', 'layer'],\n   'title': 'CH4 Wetland Emissions',\n   'description': 'Methane emissions from wetlands.'}},\n 'stac_version': '1.0.0',\n 'stac_extensions': None,\n 'dashboard:is_periodic': True,\n 'dashboard:time_density': 'month'}\n\n\nExamining the contents of our collection under summaries, we see that the data is available from January 1980 to may 2021. By looking at dashboard: time density, we can see that these observations are collected monthly.\n\ndef get_item_count(collection_id):\n    count = 0\n    items_url = f\"{STAC_API_URL}/collections/{collection_id}/items\"\n\n    while True:\n        response = requests.get(items_url)\n\n        if not response.ok:\n            print(\"error getting items\")\n            exit()\n\n        stac = response.json()\n        count += int(stac[\"context\"].get(\"returned\", 0))\n        next = [link for link in stac[\"links\"] if link[\"rel\"] == \"next\"]\n\n        if not next:\n            break\n        items_url = next[0][\"href\"]\n\n    return count\n\n\n# Check total number of items available\nnumber_of_items = get_item_count(collection_name)\nitems = requests.get(f\"{STAC_API_URL}/collections/{collection_name}/items?limit={number_of_items}\").json()[\"features\"]\nprint(f\"Found {len(items)} items\")\n\nFound 504 items\n\n\n\n# Examining the first item in the collection\nitems[0]\n\n{'id': 'lpjwsl-wetlandch4-monthgrid-v1-202112',\n 'bbox': [-180.0, -90.0, 180.0, 90.0],\n 'type': 'Feature',\n 'links': [{'rel': 'collection',\n   'type': 'application/json',\n   'href': 'https://ghg.center/api/stac/collections/lpjwsl-wetlandch4-monthgrid-v1'},\n  {'rel': 'parent',\n   'type': 'application/json',\n   'href': 'https://ghg.center/api/stac/collections/lpjwsl-wetlandch4-monthgrid-v1'},\n  {'rel': 'root',\n   'type': 'application/json',\n   'href': 'https://ghg.center/api/stac/'},\n  {'rel': 'self',\n   'type': 'application/geo+json',\n   'href': 'https://ghg.center/api/stac/collections/lpjwsl-wetlandch4-monthgrid-v1/items/lpjwsl-wetlandch4-monthgrid-v1-202112'}],\n 'assets': {'ch4-wetlands-emissions': {'href': 's3://ghgc-data-store/lpjwsl-wetlandch4-monthgrid-v1/NASA_GSFC_ch4_wl_ch4_wetlands_v22_x720_y360_t12_202112.tif',\n   'type': 'image/tiff; application=geotiff; profile=cloud-optimized',\n   'roles': ['data', 'layer'],\n   'title': 'CH4 Wetland Emissions',\n   'proj:bbox': [-180.0, -90.0, 180.0, 90.0],\n   'proj:epsg': 4326.0,\n   'proj:shape': [360.0, 720.0],\n   'description': 'Methane emissions from wetlands.',\n   'raster:bands': [{'scale': 1.0,\n     'offset': 0.0,\n     'sampling': 'area',\n     'data_type': 'float32',\n     'histogram': {'max': 6.929981708526611,\n      'min': 0.0,\n      'count': 11.0,\n      'buckets': [258080.0,\n       575.0,\n       251.0,\n       124.0,\n       78.0,\n       41.0,\n       26.0,\n       16.0,\n       7.0,\n       2.0]},\n     'statistics': {'mean': 0.012271502055227757,\n      'stddev': 0.1378920078277588,\n      'maximum': 6.929981708526611,\n      'minimum': 0.0,\n      'valid_percent': 0.0003858024691358025}}],\n   'proj:geometry': {'type': 'Polygon',\n    'coordinates': [[[-180.0, -90.0],\n      [180.0, -90.0],\n      [180.0, 90.0],\n      [-180.0, 90.0],\n      [-180.0, -90.0]]]},\n   'proj:projjson': {'id': {'code': 4326.0, 'authority': 'EPSG'},\n    'name': 'WGS 84',\n    'type': 'GeographicCRS',\n    'datum': {'name': 'World Geodetic System 1984',\n     'type': 'GeodeticReferenceFrame',\n     'ellipsoid': {'name': 'WGS 84',\n      'semi_major_axis': 6378137.0,\n      'inverse_flattening': 298.257223563}},\n    '$schema': 'https://proj.org/schemas/v0.4/projjson.schema.json',\n    'coordinate_system': {'axis': [{'name': 'Geodetic latitude',\n       'unit': 'degree',\n       'direction': 'north',\n       'abbreviation': 'Lat'},\n      {'name': 'Geodetic longitude',\n       'unit': 'degree',\n       'direction': 'east',\n       'abbreviation': 'Lon'}],\n     'subtype': 'ellipsoidal'}},\n   'proj:transform': [0.5, 0.0, -180.0, 0.0, -0.5, 90.0, 0.0, 0.0, 1.0]}},\n 'geometry': {'type': 'Polygon',\n  'coordinates': [[[-180, -90],\n    [180, -90],\n    [180, 90],\n    [-180, 90],\n    [-180, -90]]]},\n 'collection': 'lpjwsl-wetlandch4-monthgrid-v1',\n 'properties': {'datetime': '2021-12-01T00:00:00+00:00'},\n 'stac_version': '1.0.0',\n 'stac_extensions': []}\n\n\nBelow, we enter minimum and maximum values to provide our upper and lower bounds in rescale_values.\n\nrescale_values = {'max': 2.0, 'min': 0.0}"
  },
  {
    "objectID": "interactive-session-2-anthropogenic-ghg-emissions/lpjwsl-wetlandch4-grid-v1_User_Notebook.html#exploring-changes-in-methane-ch4-emission-levels-using-the-raster-api",
    "href": "interactive-session-2-anthropogenic-ghg-emissions/lpjwsl-wetlandch4-grid-v1_User_Notebook.html#exploring-changes-in-methane-ch4-emission-levels-using-the-raster-api",
    "title": "Wetland Methane Emissions, LPJ-wsl Model",
    "section": "Exploring Changes in Methane (CH4) Emission Levels Using the Raster API",
    "text": "Exploring Changes in Methane (CH4) Emission Levels Using the Raster API\nIn this notebook, we will explore the temporal impacts of methane emissions. We will visualize the outputs on a map using folium.\n\n# To access the year value from each item more easily, this will let us query more explicity by year and month (e.g., 2020-02)\nitems = {item[\"properties\"][\"datetime\"][:7]: item for item in items} \nasset_name = 'ch4-wetlands-emissions'\n\n\n# We create a area of interest (polygon) on which will be used later \n\naoi = [-95.9,-87.50,28.7,33.5]\nlouisiana_aoi = {\n    \"type\": \"Feature\",\n    \"properties\": {},\n    \"geometry\": {\n        \"coordinates\": [\n            [\n                [aoi[0], aoi[2]],\n                [aoi[0], aoi[3]],\n                [aoi[1], aoi[3]],\n                [aoi[1],aoi[2]],\n                [aoi[0], aoi[2]]\n            ]\n        ],\n        \"type\": \"Polygon\",\n    },\n}\n\nNow, we will pass the item id, collection name, and rescaling_factor to the Raster API endpoint. We will do this twice, once for may 2020 and again for may 2021, so we can visualize each event independently.\n\ncolor_map = \"magma\" # select the color ramp from matplotlib library.\nmay_2020_tile = requests.get(\n    f\"{RASTER_API_URL}/stac/tilejson.json?collection={items['2001-05']['collection']}&item={items['2020-05']['id']}\"\n    \"&assets=ch4-wetlands-emissions\"\n    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n    f\"&rescale={rescale_values['min']},{rescale_values['max']}\"\n).json()\nmay_2020_tile\n\n{'tilejson': '2.2.0',\n 'version': '1.0.0',\n 'scheme': 'xyz',\n 'tiles': ['https://ghg.center/api/raster/stac/tiles/WebMercatorQuad/{z}/{x}/{y}@1x?collection=lpjwsl-wetlandch4-monthgrid-v1&item=lpjwsl-wetlandch4-monthgrid-v1-202005&assets=ch4-wetlands-emissions&color_formula=gamma+r+1.05&colormap_name=magma&rescale=0.0%2C2.0'],\n 'minzoom': 0,\n 'maxzoom': 24,\n 'bounds': [-180.0, -90.0, 180.0, 90.0],\n 'center': [0.0, 0.0, 0]}\n\n\n\nmay_2021_tile = requests.get(\n    f\"{RASTER_API_URL}/stac/tilejson.json?collection={items['2021-05']['collection']}&item={items['2021-05']['id']}\"\n    \"&assets=ch4-wetlands-emissions\"\n    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n    f\"&rescale={rescale_values['min']},{rescale_values['max']}\", \n).json()\nmay_2021_tile\n\n{'tilejson': '2.2.0',\n 'version': '1.0.0',\n 'scheme': 'xyz',\n 'tiles': ['https://ghg.center/api/raster/stac/tiles/WebMercatorQuad/{z}/{x}/{y}@1x?collection=lpjwsl-wetlandch4-monthgrid-v1&item=lpjwsl-wetlandch4-monthgrid-v1-202105&assets=ch4-wetlands-emissions&color_formula=gamma+r+1.05&colormap_name=magma&rescale=0.0%2C2.0'],\n 'minzoom': 0,\n 'maxzoom': 24,\n 'bounds': [-180.0, -90.0, 180.0, 90.0],\n 'center': [0.0, 0.0, 0]}"
  },
  {
    "objectID": "interactive-session-2-anthropogenic-ghg-emissions/lpjwsl-wetlandch4-grid-v1_User_Notebook.html#visualizing-ch‚ÇÑ-emissions",
    "href": "interactive-session-2-anthropogenic-ghg-emissions/lpjwsl-wetlandch4-grid-v1_User_Notebook.html#visualizing-ch‚ÇÑ-emissions",
    "title": "Wetland Methane Emissions, LPJ-wsl Model",
    "section": "Visualizing CH‚ÇÑ Emissions",
    "text": "Visualizing CH‚ÇÑ Emissions\n\n# We will import folium to map and folium.plugins to allow side-by-side mapping\n# Set initial zoom and center of map for CH‚ÇÑ Layer\n# Centre of map [latitude,longitude]\n\nfrom folium.plugins import MousePosition\n\nmap_ = folium.Map(location=(30,-90), zoom_start=6)\n\n# May 2001\nmap_layer_2001 = TileLayer(\n    tiles=may_2020_tile[\"tiles\"][0],\n    attr=\"GHG\",\n    opacity=0.5,\n)\n\n\n# May 2021\nmap_layer_2021 = TileLayer(\n    tiles=may_2021_tile[\"tiles\"][0],\n    attr=\"GHG\",\n    opacity=0.5,\n)\nsbs = folium.plugins.SideBySideLayers(layer_left=map_layer_2001, layer_right=map_layer_2021)\nmap_layer_2001.add_to(map_)\nmap_layer_2021.add_to(map_)\nfolium.GeoJson(louisiana_aoi, name=\"louisiana, USA\").add_to(map_)\nsbs.add_to(map_)\nMousePosition().add_to(map_)\n# visualising the map\nmap_\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\nitems = requests.get(f\"{STAC_API_URL}/collections/{collection_name}/items?limit={number_of_items}\").json()[\"features\"]\n\n\n# The bounding box should be passed to the geojson param as a geojson Feature or FeatureCollection\n\ndef generate_stats(item, geojson):\n    result = requests.post(\n        f\"{RASTER_API_URL}/cog/statistics\",\n        params={\"url\": item[\"assets\"][\"ch4-wetlands-emissions\"][\"href\"]},\n        json=geojson,\n    ).json()\n    return {\n        **result[\"properties\"],\n        \"datetime\": item[\"properties\"][\"datetime\"],\n    }\n\nWith the function above, we can generate the statistics for the area of interest.\n\n# It will take around 5 minutes to run the statistics \n\nstats = [generate_stats(item, louisiana_aoi) for item in items[:24]]\nstats\n\n[{'statistics': {'b1': {'min': 0.0,\n    'max': 0.7171422839164734,\n    'mean': 0.15437047621783087,\n    'count': 170.0,\n    'sum': 26.24298095703125,\n    'std': 0.1835849342048151,\n    'median': 0.05701697617769241,\n    'majority': 0.0,\n    'minority': 0.00043509763781912625,\n    'unique': 123.0,\n    'histogram': [[92.0, 9.0, 13.0, 10.0, 14.0, 16.0, 7.0, 4.0, 3.0, 2.0],\n     [0.0,\n      0.07171422988176346,\n      0.14342845976352692,\n      0.21514268219470978,\n      0.28685691952705383,\n      0.3585711419582367,\n      0.43028536438941956,\n      0.5019996166229248,\n      0.5737138390541077,\n      0.6454280614852905,\n      0.7171422839164734]],\n    'valid_percent': 100.0,\n    'masked_pixels': 0.0,\n    'valid_pixels': 170.0,\n    'percentile_2': 0.0,\n    'percentile_98': 0.5802477025985717}},\n  'datetime': '2021-12-01T00:00:00+00:00'},\n {'statistics': {'b1': {'min': 0.0,\n    'max': 0.516049861907959,\n    'mean': 0.13532144883099725,\n    'count': 170.0,\n    'sum': 23.00464630126953,\n    'std': 0.15769760565780438,\n    'median': 0.05566539615392685,\n    'majority': 0.0,\n    'minority': 0.0002954523079097271,\n    'unique': 123.0,\n    'histogram': [[84.0, 13.0, 12.0, 7.0, 9.0, 12.0, 11.0, 8.0, 7.0, 7.0],\n     [0.0,\n      0.0516049861907959,\n      0.1032099723815918,\n      0.1548149585723877,\n      0.2064199447631836,\n      0.2580249309539795,\n      0.3096299171447754,\n      0.3612349033355713,\n      0.4128398895263672,\n      0.4644448757171631,\n      0.516049861907959]],\n    'valid_percent': 100.0,\n    'masked_pixels': 0.0,\n    'valid_pixels': 170.0,\n    'percentile_2': 0.0,\n    'percentile_98': 0.48761060655117044}},\n  'datetime': '2021-11-01T00:00:00+00:00'},\n {'statistics': {'b1': {'min': 0.0,\n    'max': 1.3371007442474365,\n    'mean': 0.27248965992647056,\n    'count': 170.0,\n    'sum': 46.3232421875,\n    'std': 0.32895022521723327,\n    'median': 0.08361007273197174,\n    'majority': 0.0,\n    'minority': 0.0006618715706281364,\n    'unique': 123.0,\n    'histogram': [[94.0, 10.0, 13.0, 10.0, 18.0, 10.0, 7.0, 5.0, 1.0, 2.0],\n     [0.0,\n      0.1337100714445114,\n      0.2674201428890228,\n      0.40113022923469543,\n      0.5348402857780457,\n      0.6685503721237183,\n      0.8022604584693909,\n      0.9359705448150635,\n      1.0696805715560913,\n      1.2033907175064087,\n      1.3371007442474365]],\n    'valid_percent': 100.0,\n    'masked_pixels': 0.0,\n    'valid_pixels': 170.0,\n    'percentile_2': 0.0,\n    'percentile_98': 1.060954008102417}},\n  'datetime': '2021-10-01T00:00:00+00:00'},\n {'statistics': {'b1': {'min': 0.0,\n    'max': 2.2005276679992676,\n    'mean': 0.45919602338005516,\n    'count': 170.0,\n    'sum': 78.06332397460938,\n    'std': 0.5457408213221397,\n    'median': 0.18731170892715454,\n    'majority': 0.0,\n    'minority': 0.002108836779370904,\n    'unique': 123.0,\n    'histogram': [[90.0, 15.0, 8.0, 16.0, 13.0, 11.0, 10.0, 4.0, 1.0, 2.0],\n     [0.0,\n      0.22005276381969452,\n      0.44010552763938904,\n      0.6601582765579224,\n      0.8802110552787781,\n      1.1002638339996338,\n      1.3203165531158447,\n      1.5403693914413452,\n      1.7604221105575562,\n      1.9804749488830566,\n      2.2005276679992676]],\n    'valid_percent': 100.0,\n    'masked_pixels': 0.0,\n    'valid_pixels': 170.0,\n    'percentile_2': 0.0,\n    'percentile_98': 1.6831329369544983}},\n  'datetime': '2021-09-01T00:00:00+00:00'},\n {'statistics': {'b1': {'min': 0.0,\n    'max': 2.2805004119873047,\n    'mean': 0.4716072531307445,\n    'count': 170.0,\n    'sum': 80.17323303222656,\n    'std': 0.5656065478170901,\n    'median': 0.19661885499954224,\n    'majority': 0.0,\n    'minority': 0.0015638105105608702,\n    'unique': 123.0,\n    'histogram': [[89.0, 16.0, 11.0, 13.0, 14.0, 13.0, 5.0, 5.0, 3.0, 1.0],\n     [0.0,\n      0.22805003821849823,\n      0.45610007643699646,\n      0.6841500997543335,\n      0.9122001528739929,\n      1.1402502059936523,\n      1.368300199508667,\n      1.5963503122329712,\n      1.8244003057479858,\n      2.05245041847229,\n      2.2805004119873047]],\n    'valid_percent': 100.0,\n    'masked_pixels': 0.0,\n    'valid_pixels': 170.0,\n    'percentile_2': 0.0,\n    'percentile_98': 1.8883533668518073}},\n  'datetime': '2021-08-01T00:00:00+00:00'},\n {'statistics': {'b1': {'min': 0.0,\n    'max': 3.072227716445923,\n    'mean': 0.6332277634564568,\n    'count': 170.0,\n    'sum': 107.64871978759766,\n    'std': 0.7631461866897622,\n    'median': 0.2839159667491913,\n    'majority': 0.0,\n    'minority': 0.0024779888335615396,\n    'unique': 123.0,\n    'histogram': [[91.0, 15.0, 12.0, 11.0, 13.0, 14.0, 3.0, 7.0, 3.0, 1.0],\n     [0.0,\n      0.30722278356552124,\n      0.6144455671310425,\n      0.921668291091919,\n      1.228891134262085,\n      1.5361138582229614,\n      1.843336582183838,\n      2.150559425354004,\n      2.45778226852417,\n      2.765004873275757,\n      3.072227716445923]],\n    'valid_percent': 100.0,\n    'masked_pixels': 0.0,\n    'valid_pixels': 170.0,\n    'percentile_2': 0.0,\n    'percentile_98': 2.494618062973023}},\n  'datetime': '2021-07-01T00:00:00+00:00'},\n {'statistics': {'b1': {'min': 0.0,\n    'max': 2.1353492736816406,\n    'mean': 0.5122916726505056,\n    'count': 170.0,\n    'sum': 87.08958435058594,\n    'std': 0.5816176132620369,\n    'median': 0.23781655728816986,\n    'majority': 0.0,\n    'minority': 0.002265247516334057,\n    'unique': 123.0,\n    'histogram': [[80.0, 19.0, 9.0, 9.0, 15.0, 17.0, 6.0, 7.0, 6.0, 2.0],\n     [0.0,\n      0.21353492140769958,\n      0.42706984281539917,\n      0.6406047940254211,\n      0.8541396856307983,\n      1.0676746368408203,\n      1.2812095880508423,\n      1.4947445392608643,\n      1.7082793712615967,\n      1.9218143224716187,\n      2.1353492736816406]],\n    'valid_percent': 100.0,\n    'masked_pixels': 0.0,\n    'valid_pixels': 170.0,\n    'percentile_2': 0.0,\n    'percentile_98': 1.7408480906486512}},\n  'datetime': '2021-06-01T00:00:00+00:00'},\n {'statistics': {'b1': {'min': 0.0,\n    'max': 1.7123756408691406,\n    'mean': 0.3947353587431066,\n    'count': 170.0,\n    'sum': 67.10501098632812,\n    'std': 0.4542843921906756,\n    'median': 0.16888344287872314,\n    'majority': 0.0,\n    'minority': 0.001768625108525157,\n    'unique': 123.0,\n    'histogram': [[87.0, 13.0, 9.0, 9.0, 19.0, 17.0, 3.0, 6.0, 5.0, 2.0],\n     [0.0,\n      0.17123755812644958,\n      0.34247511625289917,\n      0.5137127041816711,\n      0.6849502325057983,\n      0.8561878204345703,\n      1.0274254083633423,\n      1.1986629962921143,\n      1.3699004650115967,\n      1.5411380529403687,\n      1.7123756408691406]],\n    'valid_percent': 100.0,\n    'masked_pixels': 0.0,\n    'valid_pixels': 170.0,\n    'percentile_2': 0.0,\n    'percentile_98': 1.4123617601394653}},\n  'datetime': '2021-05-01T00:00:00+00:00'},\n {'statistics': {'b1': {'min': 0.0,\n    'max': 0.8859390616416931,\n    'mean': 0.24400625789866728,\n    'count': 170.0,\n    'sum': 41.48106384277344,\n    'std': 0.28321048400965054,\n    'median': 0.09922437369823456,\n    'majority': 0.0,\n    'minority': 0.0006858149426989257,\n    'unique': 123.0,\n    'histogram': [[84.0, 13.0, 10.0, 8.0, 5.0, 10.0, 11.0, 15.0, 7.0, 7.0],\n     [0.0,\n      0.08859390765428543,\n      0.17718781530857086,\n      0.2657817304134369,\n      0.3543756306171417,\n      0.44296953082084656,\n      0.5315634608268738,\n      0.6201573610305786,\n      0.7087512612342834,\n      0.7973451614379883,\n      0.8859390616416931]],\n    'valid_percent': 100.0,\n    'masked_pixels': 0.0,\n    'valid_pixels': 170.0,\n    'percentile_2': 0.0,\n    'percentile_98': 0.8462702941894532}},\n  'datetime': '2021-04-01T00:00:00+00:00'},\n {'statistics': {'b1': {'min': 0.0,\n    'max': 0.659404993057251,\n    'mean': 0.19500977011287915,\n    'count': 170.0,\n    'sum': 33.15166091918945,\n    'std': 0.22056241116653577,\n    'median': 0.087272509932518,\n    'majority': 0.0,\n    'minority': 0.0006441613077186048,\n    'unique': 123.0,\n    'histogram': [[79.0, 17.0, 7.0, 10.0, 5.0, 7.0, 12.0, 16.0, 4.0, 13.0],\n     [0.0,\n      0.0659404993057251,\n      0.1318809986114502,\n      0.1978214979171753,\n      0.2637619972229004,\n      0.3297024965286255,\n      0.3956429958343506,\n      0.4615834951400757,\n      0.5275239944458008,\n      0.5934644937515259,\n      0.659404993057251]],\n    'valid_percent': 100.0,\n    'masked_pixels': 0.0,\n    'valid_pixels': 170.0,\n    'percentile_2': 0.0,\n    'percentile_98': 0.6313274204730988}},\n  'datetime': '2021-03-01T00:00:00+00:00'},\n {'statistics': {'b1': {'min': 0.0,\n    'max': 0.4581904411315918,\n    'mean': 0.1083783093620749,\n    'count': 170.0,\n    'sum': 18.424312591552734,\n    'std': 0.13051518085377295,\n    'median': 0.039194926619529724,\n    'majority': 0.0,\n    'minority': 0.00028075711452402174,\n    'unique': 123.0,\n    'histogram': [[87.0, 15.0, 12.0, 9.0, 10.0, 9.0, 10.0, 8.0, 7.0, 3.0],\n     [0.0,\n      0.04581904411315918,\n      0.09163808822631836,\n      0.13745713233947754,\n      0.18327617645263672,\n      0.2290952205657959,\n      0.2749142646789551,\n      0.32073330879211426,\n      0.36655235290527344,\n      0.4123713970184326,\n      0.4581904411315918]],\n    'valid_percent': 100.0,\n    'masked_pixels': 0.0,\n    'valid_pixels': 170.0,\n    'percentile_2': 0.0,\n    'percentile_98': 0.398276316523552}},\n  'datetime': '2021-02-01T00:00:00+00:00'},\n {'statistics': {'b1': {'min': 0.0,\n    'max': 0.6753556728363037,\n    'mean': 0.1531466427971335,\n    'count': 170.0,\n    'sum': 26.034929275512695,\n    'std': 0.1810563542947181,\n    'median': 0.06246931105852127,\n    'majority': 0.0,\n    'minority': 0.0005269754328764975,\n    'unique': 123.0,\n    'histogram': [[90.0, 12.0, 11.0, 8.0, 15.0, 16.0, 4.0, 7.0, 5.0, 2.0],\n     [0.0,\n      0.06753556430339813,\n      0.13507112860679626,\n      0.2026067078113556,\n      0.27014225721359253,\n      0.33767783641815186,\n      0.4052134156227112,\n      0.4727489650249481,\n      0.5402845144271851,\n      0.6078200936317444,\n      0.6753556728363037]],\n    'valid_percent': 100.0,\n    'masked_pixels': 0.0,\n    'valid_pixels': 170.0,\n    'percentile_2': 0.0,\n    'percentile_98': 0.5708203029632569}},\n  'datetime': '2021-01-01T00:00:00+00:00'},\n {'statistics': {'b1': {'min': 0.0,\n    'max': 0.6949237585067749,\n    'mean': 0.14557975320255054,\n    'count': 170.0,\n    'sum': 24.748558044433594,\n    'std': 0.17713435804121008,\n    'median': 0.05363526940345764,\n    'majority': 0.0,\n    'minority': 0.00041759133455343544,\n    'unique': 123.0,\n    'histogram': [[93.0, 13.0, 11.0, 11.0, 13.0, 13.0, 7.0, 5.0, 1.0, 3.0],\n     [0.0,\n      0.06949237734079361,\n      0.13898475468158722,\n      0.20847712457180023,\n      0.27796950936317444,\n      0.34746187925338745,\n      0.41695424914360046,\n      0.4864466190338135,\n      0.5559390187263489,\n      0.6254313588142395,\n      0.6949237585067749]],\n    'valid_percent': 100.0,\n    'masked_pixels': 0.0,\n    'valid_pixels': 170.0,\n    'percentile_2': 0.0,\n    'percentile_98': 0.5663253521919251}},\n  'datetime': '2020-12-01T00:00:00+00:00'},\n {'statistics': {'b1': {'min': 0.0,\n    'max': 0.5358846783638,\n    'mean': 0.1278377981746898,\n    'count': 170.0,\n    'sum': 21.732425689697266,\n    'std': 0.15343874105291866,\n    'median': 0.04972578585147858,\n    'majority': 0.0,\n    'minority': 0.00028196285711601377,\n    'unique': 123.0,\n    'histogram': [[86.0, 14.0, 14.0, 8.0, 13.0, 9.0, 8.0, 8.0, 6.0, 4.0],\n     [0.0,\n      0.053588468581438065,\n      0.10717693716287613,\n      0.1607654094696045,\n      0.21435387432575226,\n      0.2679423391819,\n      0.321530818939209,\n      0.37511926889419556,\n      0.4287077486515045,\n      0.4822961986064911,\n      0.5358846783638]],\n    'valid_percent': 100.0,\n    'masked_pixels': 0.0,\n    'valid_pixels': 170.0,\n    'percentile_2': 0.0,\n    'percentile_98': 0.48206853270530703}},\n  'datetime': '2020-11-01T00:00:00+00:00'},\n {'statistics': {'b1': {'min': 0.0,\n    'max': 1.255740761756897,\n    'mean': 0.2575576333438649,\n    'count': 170.0,\n    'sum': 43.78479766845703,\n    'std': 0.31693399768408115,\n    'median': 0.0768575668334961,\n    'majority': 0.0,\n    'minority': 0.0006190046551637352,\n    'unique': 123.0,\n    'histogram': [[94.0, 13.0, 10.0, 10.0, 17.0, 9.0, 8.0, 4.0, 3.0, 2.0],\n     [0.0,\n      0.12557408213615417,\n      0.25114816427230835,\n      0.37672221660614014,\n      0.5022963285446167,\n      0.6278703808784485,\n      0.7534444332122803,\n      0.8790185451507568,\n      1.0045926570892334,\n      1.1301666498184204,\n      1.255740761756897]],\n    'valid_percent': 100.0,\n    'masked_pixels': 0.0,\n    'valid_pixels': 170.0,\n    'percentile_2': 0.0,\n    'percentile_98': 1.0394352316856386}},\n  'datetime': '2020-10-01T00:00:00+00:00'},\n {'statistics': {'b1': {'min': 0.0,\n    'max': 1.9983481168746948,\n    'mean': 0.43116993623621325,\n    'count': 170.0,\n    'sum': 73.29888916015625,\n    'std': 0.5197145296917448,\n    'median': 0.17324364185333252,\n    'majority': 0.0,\n    'minority': 0.0019067995017394423,\n    'unique': 123.0,\n    'histogram': [[89.0, 16.0, 11.0, 11.0, 13.0, 8.0, 10.0, 8.0, 2.0, 2.0],\n     [0.0,\n      0.19983480870723724,\n      0.3996696174144745,\n      0.5995044112205505,\n      0.799339234828949,\n      0.9991740584373474,\n      1.199008822441101,\n      1.3988436460494995,\n      1.598678469657898,\n      1.7985132932662964,\n      1.9983481168746948]],\n    'valid_percent': 100.0,\n    'masked_pixels': 0.0,\n    'valid_pixels': 170.0,\n    'percentile_2': 0.0,\n    'percentile_98': 1.6112784051895146}},\n  'datetime': '2020-09-01T00:00:00+00:00'},\n {'statistics': {'b1': {'min': 0.0,\n    'max': 2.0058531761169434,\n    'mean': 0.4619821436264936,\n    'count': 170.0,\n    'sum': 78.5369644165039,\n    'std': 0.5712842682229454,\n    'median': 0.16520659625530243,\n    'majority': 0.0,\n    'minority': 0.001269881846383214,\n    'unique': 123.0,\n    'histogram': [[91.0, 14.0, 11.0, 13.0, 6.0, 10.0, 6.0, 8.0, 6.0, 5.0],\n     [0.0,\n      0.20058532059192657,\n      0.40117064118385315,\n      0.6017559766769409,\n      0.8023412823677063,\n      1.0029265880584717,\n      1.2035119533538818,\n      1.4040971994400024,\n      1.6046825647354126,\n      1.8052678108215332,\n      2.0058531761169434]],\n    'valid_percent': 100.0,\n    'masked_pixels': 0.0,\n    'valid_pixels': 170.0,\n    'percentile_2': 0.0,\n    'percentile_98': 1.8289475870132446}},\n  'datetime': '2020-08-01T00:00:00+00:00'},\n {'statistics': {'b1': {'min': 0.0,\n    'max': 2.070863723754883,\n    'mean': 0.5622900570140166,\n    'count': 170.0,\n    'sum': 95.58930969238281,\n    'std': 0.6425463273519573,\n    'median': 0.2530515491962433,\n    'majority': 0.0,\n    'minority': 0.002212761202827096,\n    'unique': 123.0,\n    'histogram': [[81.0, 17.0, 9.0, 8.0, 8.0, 13.0, 10.0, 8.0, 10.0, 6.0],\n     [0.0,\n      0.20708636939525604,\n      0.4141727387905121,\n      0.6212590932846069,\n      0.8283454775810242,\n      1.0354318618774414,\n      1.2425181865692139,\n      1.4496046304702759,\n      1.6566909551620483,\n      1.8637773990631104,\n      2.070863723754883]],\n    'valid_percent': 100.0,\n    'masked_pixels': 0.0,\n    'valid_pixels': 170.0,\n    'percentile_2': 0.0,\n    'percentile_98': 1.9805018997192385}},\n  'datetime': '2020-07-01T00:00:00+00:00'},\n {'statistics': {'b1': {'min': 0.0,\n    'max': 1.6319794654846191,\n    'mean': 0.39405023911420034,\n    'count': 170.0,\n    'sum': 66.98854064941406,\n    'std': 0.4457748225152684,\n    'median': 0.1712484061717987,\n    'majority': 0.0,\n    'minority': 0.0013915648451074958,\n    'unique': 123.0,\n    'histogram': [[82.0, 18.0, 9.0, 9.0, 9.0, 18.0, 11.0, 9.0, 3.0, 2.0],\n     [0.0,\n      0.16319794952869415,\n      0.3263958990573883,\n      0.48959383368492126,\n      0.6527917981147766,\n      0.8159897327423096,\n      0.9791876673698425,\n      1.1423856019973755,\n      1.3055835962295532,\n      1.4687814712524414,\n      1.6319794654846191]],\n    'valid_percent': 100.0,\n    'masked_pixels': 0.0,\n    'valid_pixels': 170.0,\n    'percentile_2': 0.0,\n    'percentile_98': 1.3640193176269535}},\n  'datetime': '2020-06-01T00:00:00+00:00'},\n {'statistics': {'b1': {'min': 0.0,\n    'max': 1.4179749488830566,\n    'mean': 0.3024932861328125,\n    'count': 170.0,\n    'sum': 51.423858642578125,\n    'std': 0.35093550103567694,\n    'median': 0.12169831991195679,\n    'majority': 0.0,\n    'minority': 0.001449149684049189,\n    'unique': 123.0,\n    'histogram': [[88.0, 13.0, 10.0, 17.0, 12.0, 16.0, 7.0, 4.0, 0.0, 3.0],\n     [0.0,\n      0.1417974978685379,\n      0.2835949957370758,\n      0.4253924787044525,\n      0.5671899914741516,\n      0.7089874744415283,\n      0.850784957408905,\n      0.9925824403762817,\n      1.1343799829483032,\n      1.2761774063110352,\n      1.4179749488830566]],\n    'valid_percent': 100.0,\n    'masked_pixels': 0.0,\n    'valid_pixels': 170.0,\n    'percentile_2': 0.0,\n    'percentile_98': 1.092334604263306}},\n  'datetime': '2020-05-01T00:00:00+00:00'},\n {'statistics': {'b1': {'min': 0.0,\n    'max': 0.9126242399215698,\n    'mean': 0.20955680398380055,\n    'count': 170.0,\n    'sum': 35.624656677246094,\n    'std': 0.23214241630129956,\n    'median': 0.10675151646137238,\n    'majority': 0.0,\n    'minority': 0.0011147678596898913,\n    'unique': 123.0,\n    'histogram': [[80.0, 17.0, 11.0, 12.0, 23.0, 9.0, 10.0, 5.0, 1.0, 2.0],\n     [0.0,\n      0.09126242250204086,\n      0.18252484500408173,\n      0.273787260055542,\n      0.36504969000816345,\n      0.4563121199607849,\n      0.547574520111084,\n      0.6388369798660278,\n      0.7300993800163269,\n      0.8213618397712708,\n      0.9126242399215698]],\n    'valid_percent': 100.0,\n    'masked_pixels': 0.0,\n    'valid_pixels': 170.0,\n    'percentile_2': 0.0,\n    'percentile_98': 0.7237258589267731}},\n  'datetime': '2020-04-01T00:00:00+00:00'},\n {'statistics': {'b1': {'min': 0.0,\n    'max': 1.0447851419448853,\n    'mean': 0.22874827665441178,\n    'count': 170.0,\n    'sum': 38.88720703125,\n    'std': 0.25775953751223146,\n    'median': 0.10438993573188782,\n    'majority': 0.0,\n    'minority': 0.0009839008562266827,\n    'unique': 123.0,\n    'histogram': [[86.0, 15.0, 9.0, 13.0, 14.0, 20.0, 9.0, 1.0, 2.0, 1.0],\n     [0.0,\n      0.10447851568460464,\n      0.2089570313692093,\n      0.31343555450439453,\n      0.4179140627384186,\n      0.5223925709724426,\n      0.6268711090087891,\n      0.7313495874404907,\n      0.8358281254768372,\n      0.9403066039085388,\n      1.0447851419448853]],\n    'valid_percent': 100.0,\n    'masked_pixels': 0.0,\n    'valid_pixels': 170.0,\n    'percentile_2': 0.0,\n    'percentile_98': 0.7838775122165684}},\n  'datetime': '2020-03-01T00:00:00+00:00'},\n {'statistics': {'b1': {'min': 0.0,\n    'max': 0.7303400635719299,\n    'mean': 0.1730064167695887,\n    'count': 170.0,\n    'sum': 29.411090850830078,\n    'std': 0.2041394445830063,\n    'median': 0.06572374701499939,\n    'majority': 0.0,\n    'minority': 0.0005588305648416281,\n    'unique': 123.0,\n    'histogram': [[86.0, 15.0, 12.0, 8.0, 13.0, 10.0, 12.0, 7.0, 4.0, 3.0],\n     [0.0,\n      0.07303400337696075,\n      0.1460680067539215,\n      0.21910202503204346,\n      0.292136013507843,\n      0.36517003178596497,\n      0.4382040500640869,\n      0.5112380385398865,\n      0.584272027015686,\n      0.6573060750961304,\n      0.7303400635719299]],\n    'valid_percent': 100.0,\n    'masked_pixels': 0.0,\n    'valid_pixels': 170.0,\n    'percentile_2': 0.0,\n    'percentile_98': 0.6206122100353242}},\n  'datetime': '2020-02-01T00:00:00+00:00'},\n {'statistics': {'b1': {'min': 0.0,\n    'max': 0.7433937788009644,\n    'mean': 0.17906734242158778,\n    'count': 170.0,\n    'sum': 30.441448211669922,\n    'std': 0.20951516248017335,\n    'median': 0.06703908741474152,\n    'majority': 0.0,\n    'minority': 0.0004158392839599401,\n    'unique': 123.0,\n    'histogram': [[88.0, 12.0, 11.0, 9.0, 10.0, 13.0, 12.0, 8.0, 5.0, 2.0],\n     [0.0,\n      0.0743393748998642,\n      0.1486787497997284,\n      0.22301813960075378,\n      0.2973574995994568,\n      0.3716968894004822,\n      0.44603627920150757,\n      0.520375669002533,\n      0.5947149991989136,\n      0.669054388999939,\n      0.7433937788009644]],\n    'valid_percent': 100.0,\n    'masked_pixels': 0.0,\n    'valid_pixels': 170.0,\n    'percentile_2': 0.0,\n    'percentile_98': 0.637993005514145}},\n  'datetime': '2020-01-01T00:00:00+00:00'}]\n\n\n\n# Manipulating and cleaning the stats output from previous cell\n\ndef clean_stats(stats_json) -&gt; pd.DataFrame:\n    df = pd.json_normalize(stats_json)\n    df.columns = [col.replace(\"statistics.b1.\", \"\") for col in df.columns]\n    df[\"date\"] = pd.to_datetime(df[\"datetime\"])\n    return df\n\n\ndf = clean_stats(stats)\ndf.head(5)\n\n\n\n\n\n\n\n\ndatetime\nmin\nmax\nmean\ncount\nsum\nstd\nmedian\nmajority\nminority\nunique\nhistogram\nvalid_percent\nmasked_pixels\nvalid_pixels\npercentile_2\npercentile_98\ndate\n\n\n\n\n0\n2021-12-01T00:00:00+00:00\n0.0\n0.717142\n0.154370\n170.0\n26.242981\n0.183585\n0.057017\n0.0\n0.000435\n123.0\n[[92.0, 9.0, 13.0, 10.0, 14.0, 16.0, 7.0, 4.0,...\n100.0\n0.0\n170.0\n0.0\n0.580248\n2021-12-01 00:00:00+00:00\n\n\n1\n2021-11-01T00:00:00+00:00\n0.0\n0.516050\n0.135321\n170.0\n23.004646\n0.157698\n0.055665\n0.0\n0.000295\n123.0\n[[84.0, 13.0, 12.0, 7.0, 9.0, 12.0, 11.0, 8.0,...\n100.0\n0.0\n170.0\n0.0\n0.487611\n2021-11-01 00:00:00+00:00\n\n\n2\n2021-10-01T00:00:00+00:00\n0.0\n1.337101\n0.272490\n170.0\n46.323242\n0.328950\n0.083610\n0.0\n0.000662\n123.0\n[[94.0, 10.0, 13.0, 10.0, 18.0, 10.0, 7.0, 5.0...\n100.0\n0.0\n170.0\n0.0\n1.060954\n2021-10-01 00:00:00+00:00\n\n\n3\n2021-09-01T00:00:00+00:00\n0.0\n2.200528\n0.459196\n170.0\n78.063324\n0.545741\n0.187312\n0.0\n0.002109\n123.0\n[[90.0, 15.0, 8.0, 16.0, 13.0, 11.0, 10.0, 4.0...\n100.0\n0.0\n170.0\n0.0\n1.683133\n2021-09-01 00:00:00+00:00\n\n\n4\n2021-08-01T00:00:00+00:00\n0.0\n2.280500\n0.471607\n170.0\n80.173233\n0.565607\n0.196619\n0.0\n0.001564\n123.0\n[[89.0, 16.0, 11.0, 13.0, 14.0, 13.0, 5.0, 5.0...\n100.0\n0.0\n170.0\n0.0\n1.888353\n2021-08-01 00:00:00+00:00\n\n\n\n\n\n\n\n\n# Filtering the stats for year 2020 and 2021\n\ndf_2020_2021 = df[(df['date'].dt.year == 2020) | (df['date'].dt.year == 2021)]\ndf_2020_2021['year'] = pd.to_datetime(df_2020_2021['datetime']).dt.year\ndf_2020_2021['month'] = pd.to_datetime(df_2020_2021['datetime']).dt.month\ndf_2020_2021\n\n\n\n\n\n\n\n\ndatetime\nmin\nmax\nmean\ncount\nsum\nstd\nmedian\nmajority\nminority\nunique\nhistogram\nvalid_percent\nmasked_pixels\nvalid_pixels\npercentile_2\npercentile_98\ndate\nyear\nmonth\n\n\n\n\n0\n2021-12-01T00:00:00+00:00\n0.0\n0.717142\n0.154370\n170.0\n26.242981\n0.183585\n0.057017\n0.0\n0.000435\n123.0\n[[92.0, 9.0, 13.0, 10.0, 14.0, 16.0, 7.0, 4.0,...\n100.0\n0.0\n170.0\n0.0\n0.580248\n2021-12-01 00:00:00+00:00\n2021\n12\n\n\n1\n2021-11-01T00:00:00+00:00\n0.0\n0.516050\n0.135321\n170.0\n23.004646\n0.157698\n0.055665\n0.0\n0.000295\n123.0\n[[84.0, 13.0, 12.0, 7.0, 9.0, 12.0, 11.0, 8.0,...\n100.0\n0.0\n170.0\n0.0\n0.487611\n2021-11-01 00:00:00+00:00\n2021\n11\n\n\n2\n2021-10-01T00:00:00+00:00\n0.0\n1.337101\n0.272490\n170.0\n46.323242\n0.328950\n0.083610\n0.0\n0.000662\n123.0\n[[94.0, 10.0, 13.0, 10.0, 18.0, 10.0, 7.0, 5.0...\n100.0\n0.0\n170.0\n0.0\n1.060954\n2021-10-01 00:00:00+00:00\n2021\n10\n\n\n3\n2021-09-01T00:00:00+00:00\n0.0\n2.200528\n0.459196\n170.0\n78.063324\n0.545741\n0.187312\n0.0\n0.002109\n123.0\n[[90.0, 15.0, 8.0, 16.0, 13.0, 11.0, 10.0, 4.0...\n100.0\n0.0\n170.0\n0.0\n1.683133\n2021-09-01 00:00:00+00:00\n2021\n9\n\n\n4\n2021-08-01T00:00:00+00:00\n0.0\n2.280500\n0.471607\n170.0\n80.173233\n0.565607\n0.196619\n0.0\n0.001564\n123.0\n[[89.0, 16.0, 11.0, 13.0, 14.0, 13.0, 5.0, 5.0...\n100.0\n0.0\n170.0\n0.0\n1.888353\n2021-08-01 00:00:00+00:00\n2021\n8\n\n\n5\n2021-07-01T00:00:00+00:00\n0.0\n3.072228\n0.633228\n170.0\n107.648720\n0.763146\n0.283916\n0.0\n0.002478\n123.0\n[[91.0, 15.0, 12.0, 11.0, 13.0, 14.0, 3.0, 7.0...\n100.0\n0.0\n170.0\n0.0\n2.494618\n2021-07-01 00:00:00+00:00\n2021\n7\n\n\n6\n2021-06-01T00:00:00+00:00\n0.0\n2.135349\n0.512292\n170.0\n87.089584\n0.581618\n0.237817\n0.0\n0.002265\n123.0\n[[80.0, 19.0, 9.0, 9.0, 15.0, 17.0, 6.0, 7.0, ...\n100.0\n0.0\n170.0\n0.0\n1.740848\n2021-06-01 00:00:00+00:00\n2021\n6\n\n\n7\n2021-05-01T00:00:00+00:00\n0.0\n1.712376\n0.394735\n170.0\n67.105011\n0.454284\n0.168883\n0.0\n0.001769\n123.0\n[[87.0, 13.0, 9.0, 9.0, 19.0, 17.0, 3.0, 6.0, ...\n100.0\n0.0\n170.0\n0.0\n1.412362\n2021-05-01 00:00:00+00:00\n2021\n5\n\n\n8\n2021-04-01T00:00:00+00:00\n0.0\n0.885939\n0.244006\n170.0\n41.481064\n0.283210\n0.099224\n0.0\n0.000686\n123.0\n[[84.0, 13.0, 10.0, 8.0, 5.0, 10.0, 11.0, 15.0...\n100.0\n0.0\n170.0\n0.0\n0.846270\n2021-04-01 00:00:00+00:00\n2021\n4\n\n\n9\n2021-03-01T00:00:00+00:00\n0.0\n0.659405\n0.195010\n170.0\n33.151661\n0.220562\n0.087273\n0.0\n0.000644\n123.0\n[[79.0, 17.0, 7.0, 10.0, 5.0, 7.0, 12.0, 16.0,...\n100.0\n0.0\n170.0\n0.0\n0.631327\n2021-03-01 00:00:00+00:00\n2021\n3\n\n\n10\n2021-02-01T00:00:00+00:00\n0.0\n0.458190\n0.108378\n170.0\n18.424313\n0.130515\n0.039195\n0.0\n0.000281\n123.0\n[[87.0, 15.0, 12.0, 9.0, 10.0, 9.0, 10.0, 8.0,...\n100.0\n0.0\n170.0\n0.0\n0.398276\n2021-02-01 00:00:00+00:00\n2021\n2\n\n\n11\n2021-01-01T00:00:00+00:00\n0.0\n0.675356\n0.153147\n170.0\n26.034929\n0.181056\n0.062469\n0.0\n0.000527\n123.0\n[[90.0, 12.0, 11.0, 8.0, 15.0, 16.0, 4.0, 7.0,...\n100.0\n0.0\n170.0\n0.0\n0.570820\n2021-01-01 00:00:00+00:00\n2021\n1\n\n\n12\n2020-12-01T00:00:00+00:00\n0.0\n0.694924\n0.145580\n170.0\n24.748558\n0.177134\n0.053635\n0.0\n0.000418\n123.0\n[[93.0, 13.0, 11.0, 11.0, 13.0, 13.0, 7.0, 5.0...\n100.0\n0.0\n170.0\n0.0\n0.566325\n2020-12-01 00:00:00+00:00\n2020\n12\n\n\n13\n2020-11-01T00:00:00+00:00\n0.0\n0.535885\n0.127838\n170.0\n21.732426\n0.153439\n0.049726\n0.0\n0.000282\n123.0\n[[86.0, 14.0, 14.0, 8.0, 13.0, 9.0, 8.0, 8.0, ...\n100.0\n0.0\n170.0\n0.0\n0.482069\n2020-11-01 00:00:00+00:00\n2020\n11\n\n\n14\n2020-10-01T00:00:00+00:00\n0.0\n1.255741\n0.257558\n170.0\n43.784798\n0.316934\n0.076858\n0.0\n0.000619\n123.0\n[[94.0, 13.0, 10.0, 10.0, 17.0, 9.0, 8.0, 4.0,...\n100.0\n0.0\n170.0\n0.0\n1.039435\n2020-10-01 00:00:00+00:00\n2020\n10\n\n\n15\n2020-09-01T00:00:00+00:00\n0.0\n1.998348\n0.431170\n170.0\n73.298889\n0.519715\n0.173244\n0.0\n0.001907\n123.0\n[[89.0, 16.0, 11.0, 11.0, 13.0, 8.0, 10.0, 8.0...\n100.0\n0.0\n170.0\n0.0\n1.611278\n2020-09-01 00:00:00+00:00\n2020\n9\n\n\n16\n2020-08-01T00:00:00+00:00\n0.0\n2.005853\n0.461982\n170.0\n78.536964\n0.571284\n0.165207\n0.0\n0.001270\n123.0\n[[91.0, 14.0, 11.0, 13.0, 6.0, 10.0, 6.0, 8.0,...\n100.0\n0.0\n170.0\n0.0\n1.828948\n2020-08-01 00:00:00+00:00\n2020\n8\n\n\n17\n2020-07-01T00:00:00+00:00\n0.0\n2.070864\n0.562290\n170.0\n95.589310\n0.642546\n0.253052\n0.0\n0.002213\n123.0\n[[81.0, 17.0, 9.0, 8.0, 8.0, 13.0, 10.0, 8.0, ...\n100.0\n0.0\n170.0\n0.0\n1.980502\n2020-07-01 00:00:00+00:00\n2020\n7\n\n\n18\n2020-06-01T00:00:00+00:00\n0.0\n1.631979\n0.394050\n170.0\n66.988541\n0.445775\n0.171248\n0.0\n0.001392\n123.0\n[[82.0, 18.0, 9.0, 9.0, 9.0, 18.0, 11.0, 9.0, ...\n100.0\n0.0\n170.0\n0.0\n1.364019\n2020-06-01 00:00:00+00:00\n2020\n6\n\n\n19\n2020-05-01T00:00:00+00:00\n0.0\n1.417975\n0.302493\n170.0\n51.423859\n0.350936\n0.121698\n0.0\n0.001449\n123.0\n[[88.0, 13.0, 10.0, 17.0, 12.0, 16.0, 7.0, 4.0...\n100.0\n0.0\n170.0\n0.0\n1.092335\n2020-05-01 00:00:00+00:00\n2020\n5\n\n\n20\n2020-04-01T00:00:00+00:00\n0.0\n0.912624\n0.209557\n170.0\n35.624657\n0.232142\n0.106752\n0.0\n0.001115\n123.0\n[[80.0, 17.0, 11.0, 12.0, 23.0, 9.0, 10.0, 5.0...\n100.0\n0.0\n170.0\n0.0\n0.723726\n2020-04-01 00:00:00+00:00\n2020\n4\n\n\n21\n2020-03-01T00:00:00+00:00\n0.0\n1.044785\n0.228748\n170.0\n38.887207\n0.257760\n0.104390\n0.0\n0.000984\n123.0\n[[86.0, 15.0, 9.0, 13.0, 14.0, 20.0, 9.0, 1.0,...\n100.0\n0.0\n170.0\n0.0\n0.783878\n2020-03-01 00:00:00+00:00\n2020\n3\n\n\n22\n2020-02-01T00:00:00+00:00\n0.0\n0.730340\n0.173006\n170.0\n29.411091\n0.204139\n0.065724\n0.0\n0.000559\n123.0\n[[86.0, 15.0, 12.0, 8.0, 13.0, 10.0, 12.0, 7.0...\n100.0\n0.0\n170.0\n0.0\n0.620612\n2020-02-01 00:00:00+00:00\n2020\n2\n\n\n23\n2020-01-01T00:00:00+00:00\n0.0\n0.743394\n0.179067\n170.0\n30.441448\n0.209515\n0.067039\n0.0\n0.000416\n123.0\n[[88.0, 12.0, 11.0, 9.0, 10.0, 13.0, 12.0, 8.0...\n100.0\n0.0\n170.0\n0.0\n0.637993\n2020-01-01 00:00:00+00:00\n2020\n1"
  },
  {
    "objectID": "interactive-session-2-anthropogenic-ghg-emissions/lpjwsl-wetlandch4-grid-v1_User_Notebook.html#visualizing-the-data-as-a-time-series",
    "href": "interactive-session-2-anthropogenic-ghg-emissions/lpjwsl-wetlandch4-grid-v1_User_Notebook.html#visualizing-the-data-as-a-time-series",
    "title": "Wetland Methane Emissions, LPJ-wsl Model",
    "section": "Visualizing the Data as a Time Series",
    "text": "Visualizing the Data as a Time Series\nWe can now explore the wetland methane emissions time series (January - December) for the year 2020,2021 available for the Louisiana area of the U.S. We can plot the data set using the code below:\n\nitems = {item[\"properties\"][\"datetime\"][:7]: item for item in items} \nfig = plt.figure(figsize=(20, 10))\n\nsns.lineplot(\n    df_2020_2021,\n    x = 'month', \n    y = 'sum',\n    hue= 'year',\n    palette='flare'\n)\n\n# plt.legend()\nplt.xlabel(\"months\")\nplt.ylabel(\"CH4 emissions g/m2\")\nplt.title(\"CH4 emission Values for Louisiana for 2020 and 2021\")\n\n\ncolormap = cm.LinearColormap(colors = ['#2c115f','#721f81','#b73779','#f1605d','#feb078'], vmin = 0, vmax = 2 )\ncolormap.caption = 'g CH‚ÇÑ/m¬≤/day'\n\nmay_2021_tile = requests.get(\n    f\"{RASTER_API_URL}/stac/tilejson.json?collection={items['2021-05']['collection']}&item={items['2021-05']['id']}\"\n    \"&assets=ch4-wetlands-emissions\"\n    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n    f\"&rescale={rescale_values['min']},{rescale_values['max']}\", \n).json()\nmay_2021_tile\njune_2021_tile = requests.get(\n    f\"{RASTER_API_URL}/stac/tilejson.json?collection={items['2021-06']['collection']}&item={items['2021-06']['id']}\"\n    \"&assets=ch4-wetlands-emissions\"\n    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n    f\"&rescale={rescale_values['min']},{rescale_values['max']}\", \n).json()\njune_2021_tile\njuly_2021_tile = requests.get(\n    f\"{RASTER_API_URL}/stac/tilejson.json?collection={items['2021-07']['collection']}&item={items['2021-07']['id']}\"\n    \"&assets=ch4-wetlands-emissions\"\n    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n    f\"&rescale={rescale_values['min']},{rescale_values['max']}\", \n).json()\njuly_2021_tile\n\nmap_ = folium.Map(location=(30,-90), zoom_start=5)\n\n# May 2001\nmap_layer_202105 = TileLayer(\n    tiles=may_2020_tile[\"tiles\"][0],\n    attr=\"GHG\",\n    opacity=0.5,\n    name='May'\n)\nmap_layer_202105.add_to(map_)\n\n# May 2021\nmap_layer_202106 = TileLayer(\n    tiles=june_2021_tile[\"tiles\"][0],\n    attr=\"GHG\",\n    opacity=0.5,\n    name='June'\n)\nmap_layer_202106.add_to(map_)\n\nmap_layer_202107 = TileLayer(\n    tiles=july_2021_tile[\"tiles\"][0],\n    attr=\"GHG\",\n    opacity=0.5,\n    name='July'\n)\nmap_layer_202107.add_to(map_)\n\nfolium.GeoJson(louisiana_aoi, name=\"louisiana, USA\").add_to(map_)\nfolium.LayerControl(collapsed=False,position='bottomleft').add_to(map_)\n\nsvg_style = '&lt;style&gt;svg#legend {font-size: 14px; background-color: white;}&lt;/style&gt;'\nmap_.get_root().header.add_child(folium.Element(svg_style))\nmap_.add_child(colormap)\n# visualising the map\nmap_\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\n\n\nMERRA2 visualization\n\nmerra_t2m_dir='merra_t2m_dir/'\nmerra_soil_moisture_dir = 'merra_soil_moisture_dir/'\nmerra_precip_rate_dir = 'merra_precip_rate_dir/'\nmerra_t2m_clim_dir = 'merra_t2m_clim_dir/'\nsavedir = 'saved_files'\n\nmerra_precip_rate_clim_dir = merra_t2m_clim_dir \nmerra_soil_moisture_clim_dir = merra_t2m_clim_dir\n\n\nparams={\n    'MERRA-2 T2M':\n        {'var':'T2M',\n        'cmap':'Spectral_r',\n        'dir':merra_t2m_dir,\n        'nickname':'merra2_t2m',\n        'climdir':merra_t2m_clim_dir,\n        'climvar':'T2MMEAN'},\n    'MERRA-2 Surface Soil Moisture':\n        {'var':'GWETTOP',\n        'cmap':'Blues',\n        'dir':merra_soil_moisture_dir,\n        'nickname':'merra2_sm',\n        'climdir':merra_soil_moisture_clim_dir,\n        'climvar':'GWETTOP'},\n    'MERRA-2 Precipitation Rate':\n        {'var':'PRECTOT',\n        'cmap':'Spectral_r',\n        'dir':merra_precip_rate_dir,\n        'nickname':'merra2_pr',\n        'climdir':merra_precip_rate_clim_dir,\n        'climvar':'PRECTOT'}\n}\n\nboundaries={\n    'Global':[-180,180,-90,90],\n    'Louisiana': [-95.9,-87.50,28.7,33.5],\n    'CONUS':[-127.08,-63.87,23.55,49.19],   #   conus\n    'Florida':[-84.07,-79.14,24.85,30.5],\n    'Northeast':[-74.88,-69.81,40.48,42.88]\n}\n\nyear=1991\nfocus = 'Northeast'\nanomaly = 1\nparam = ['MERRA-2 Precipitation Rate','MERRA-2 Surface Soil Moisture', 'MERRA-2 T2M' ]\n\n\ndef get_merra2_timeseries(year,focus,p,anomaly):\n    files = glob.glob(params[p]['dir']+'*.nc4')\n    if anomaly:\n        try:\n            clim_files = glob.glob(params[p]['climdir']+'*.nc4')\n        except:\n            print('Climatological mean files (climdir) not found for specified parameter.')\n            breakpoint()\n    month_labels = []\n    box_totals = []\n    month_field = []\n    dt = []\n    for i,f in enumerate(files):\n        data = nc.Dataset(f)\n        \n        #   Get bounding box\n        wlat = np.logical_and(\n            data['lat'][:] &lt; boundaries[focus][3],\n            data['lat'][:] &gt; boundaries[focus][2]\n        )\n        wlon = np.logical_and(\n            data['lon'][:] &lt; boundaries[focus][1],\n            data['lon'][:] &gt; boundaries[focus][0]\n        )\n\n        datestamp = f.split('.')[-2]\n        month = int(datestamp[-2::])\n\n        dt.append(datetime(year,month,1))\n        month_labels.append(datetime(year,month,1).strftime('%B'))\n\n        if anomaly:\n            #   Make sure you read the climatology for the right month (whichfile)\n            whichfile = [datetime(1991,month,1).strftime('%y%m')[1:] in f for f in clim_files]\n            climdata = nc.Dataset(np.array(clim_files)[whichfile][0])\n            \n            #   Calculate sum (emissions) or mean (met params) over your bounding box\n            if 'LPJ' in p:\n                clim_box_total = np.nansum(climdata[params[p]['climvar']][0,wlat,wlon])\n                now_box_total = np.nansum(data[params[p]['var']][0,wlat,wlon])\n            elif 'MERRA' in p:\n                clim_box_total = np.nanmean(climdata[params[p]['climvar']][0,wlat,wlon])\n                now_box_total = np.nanmean(data[params[p]['var']][0,wlat,wlon])\n\n            #   Replace fill values with NaN \n            #   Otherwise differencing might give wild results? (Just be safe)\n            wfillclim = np.where(climdata[params[p]['climvar']][0,:,:] == climdata[params[p]['climvar']]._FillValue)\n            climfield = climdata[params[p]['climvar']][0,:,:]\n            climfield[wfillclim] = np.nan\n            wfillnow = np.where(data[params[p]['var']][0,:,:] == data[params[p]['var']]._FillValue)\n            nowfield = data[params[p]['var']][0,:,:]\n            nowfield[wfillnow] = np.nan\n\n            #   And finally, difference current month and long-term mean \n            box_totals.append(now_box_total - clim_box_total)\n            month_field.append(nowfield - climfield)\n            climdata.close()\n        else:\n            if 'LPJ' in p:\n                box_totals.append(np.nansum(data[params[p]['var']][0,wlat,wlon]))\n            elif 'MERRA' in p:\n                box_totals.append(np.nanmean(data[params[p]['var']][0,wlat,wlon]))\n            #   Replace fill values with NaN (otherwise maps are hard to read) \n            month_field.append(data[params[p]['var']][0,:,:])\n            wfill = np.where(month_field[-1] == data[params[p]['var']]._FillValue)\n            month_field[-1][wfill] = np.nan\n            #breakpoint()\n\n    #   Sort in case months are out of order\n    dti = np.argsort(dt)\n    month_labels = np.array(month_labels)[dti]\n    box_totals = np.array(box_totals)[dti]\n    month_field = np.array(month_field)[dti]\n\n    # print('mean ',np.nanmean(month_field))\n    # print('std ',np.nanstd(month_field))\n\n    data_return = {\n        'month_labels':month_labels,\n        'box_totals':box_totals,\n        'month_fields':month_field,\n        'units':data[params[p]['var']].units,\n        'lat':data['lat'][:],\n        'lon':data['lon'][:],\n        'mean':np.nanmean(month_field),\n        'std' : np.nanstd(month_field)\n    }\n    data.close()\n    return data_return \n\n\ncmap = plt.get_cmap('gnuplot') \ncolors = cmap(np.linspace(0,1,len(param)))\nfor i,p in enumerate(param):\n    \n    ts = get_merra2_timeseries(year,focus,p,anomaly)\n    print(f'Mean of variable {p} is {ts[\"mean\"]}')\n    print(f'Standard deviation of variable {p} is {ts[\"std\"]}')\n        \n    # if i == 0:\n    fig= plt.figure(figsize=(6,3))\n    ax = fig.add_subplot(1,1,1)\n\n    #breakpoint()\n    try:\n        ax.plot(\n            list(range(0,12)),\n            ts['box_totals'],\n            linestyle='-',\n            linewidth=2,\n            color=colors[i],\n            markersize=4,\n            marker='o',\n            label=p\n        )\n    except ValueError:\n        print('Double check that you have all twelve months of MERRA-2 data downloaded!')\n        print(params[p]['dir'])\n        breakpoint()\n\n    #   Construct plot title\n    title = '%s\\n%s Mean Monthly %s'%(focus,year,p)\n    if anomaly:\n        title+=' Anomaly' \n    if 'LPJ' in p:\n        title = title.replace('Mean','Total')\n    plt.title(title)\n    \n    plt.xticks(list(range(0,12)))\n    ax.set_xticklabels(ts['month_labels'],rotation=40,ha='right')\n\n\n    ax.legend(loc='best')\n    nickname = params[p]['nickname']\n    savename = '%s/box_summed_%s_%s_%s.png'% \\\n        (savedir,nickname,year,focus)\n    if anomaly:\n        ax.plot(list(range(-1,13)),np.zeros(14),linewidth=0.4)\n        savename = savename.replace('.png','_Anomaly.png')\n    ax.set_xlim(-1,12)\n    ax.set_ylim(min(ts['box_totals']),max(ts['box_totals']))     #   manual per parameter\n    # print('Saving to '+savename)\n    plt.show()\n    plt.savefig('saved_files/'+savename.split('/')[-1],dpi=300,bbox_inches='tight')\n\nMean of variable MERRA-2 Precipitation Rate is -7.973682727424602e-07\nStandard deviation of variable MERRA-2 Precipitation Rate is 1.885925667011179e-05\nMean of variable MERRA-2 Surface Soil Moisture is -0.00156168092507869\nStandard deviation of variable MERRA-2 Surface Soil Moisture is 0.0329766683280468\nMean of variable MERRA-2 T2M is -0.08452282100915909\nStandard deviation of variable MERRA-2 T2M is 1.4482206106185913\n\n\n\n\n\n&lt;Figure size 640x480 with 0 Axes&gt;\n\n\n\n\n\n&lt;Figure size 640x480 with 0 Axes&gt;\n\n\n\n\n\n&lt;Figure size 640x480 with 0 Axes&gt;"
  },
  {
    "objectID": "interactive-session-2-anthropogenic-ghg-emissions/lpjwsl-wetlandch4-grid-v1_User_Notebook.html#summary",
    "href": "interactive-session-2-anthropogenic-ghg-emissions/lpjwsl-wetlandch4-grid-v1_User_Notebook.html#summary",
    "title": "Wetland Methane Emissions, LPJ-wsl Model",
    "section": "Summary",
    "text": "Summary\nIn this notebook, we have successfully explored, analyzed, and visualized the STAC collection for wetland methane emissions and MERRA-2 data."
  },
  {
    "objectID": "interactive-session-2-anthropogenic-ghg-emissions/index.html",
    "href": "interactive-session-2-anthropogenic-ghg-emissions/index.html",
    "title": "Complementing anthropogenic GHG emissions with natural GHG emissions and fluxes",
    "section": "",
    "text": "Complementing anthropogenic GHG emissions with natural GHG emissions and fluxes"
  },
  {
    "objectID": "interactive-session-1-epa-gridded-methane-emissions/odiac-ffco2-monthgrid-v2022_User_Notebook.html",
    "href": "interactive-session-1-epa-gridded-methane-emissions/odiac-ffco2-monthgrid-v2022_User_Notebook.html",
    "title": "ODIAC Fossil Fuel CO‚ÇÇ Emissions",
    "section": "",
    "text": "Identify available dates and temporal frequency of observations for the given collection using the GHGC API /stac endpoint. Collection processed in this notebook is ODIAC CO‚ÇÇ emissions version 2022.\nPass the STAC item into raster API /stac/tilejson.json endpoint\nWe‚Äôll visualize two tiles (side-by-side) allowing for comparison of each of the time points using folium.plugins.DualMap\nAfter the visualization, we‚Äôll perform zonal statistics for a given polygon."
  },
  {
    "objectID": "interactive-session-1-epa-gridded-methane-emissions/odiac-ffco2-monthgrid-v2022_User_Notebook.html#approach",
    "href": "interactive-session-1-epa-gridded-methane-emissions/odiac-ffco2-monthgrid-v2022_User_Notebook.html#approach",
    "title": "ODIAC Fossil Fuel CO‚ÇÇ Emissions",
    "section": "",
    "text": "Identify available dates and temporal frequency of observations for the given collection using the GHGC API /stac endpoint. Collection processed in this notebook is ODIAC CO‚ÇÇ emissions version 2022.\nPass the STAC item into raster API /stac/tilejson.json endpoint\nWe‚Äôll visualize two tiles (side-by-side) allowing for comparison of each of the time points using folium.plugins.DualMap\nAfter the visualization, we‚Äôll perform zonal statistics for a given polygon."
  },
  {
    "objectID": "interactive-session-1-epa-gridded-methane-emissions/odiac-ffco2-monthgrid-v2022_User_Notebook.html#about-the-data",
    "href": "interactive-session-1-epa-gridded-methane-emissions/odiac-ffco2-monthgrid-v2022_User_Notebook.html#about-the-data",
    "title": "ODIAC Fossil Fuel CO‚ÇÇ Emissions",
    "section": "About the Data",
    "text": "About the Data\nThe Open-Data Inventory for Anthropogenic Carbon dioxide (ODIAC) is a high-spatial resolution global emission data product of CO‚ÇÇ emissions from fossil fuel combustion (Oda and Maksyutov, 2011). ODIAC pioneered the combined use of space-based nighttime light data and individual power plant emission/location profiles to estimate the global spatial extent of fossil fuel CO‚ÇÇ emissions. With the innovative emission modeling approach, ODIAC achieved the fine picture of global fossil fuel CO‚ÇÇ emissions at a 1x1km."
  },
  {
    "objectID": "interactive-session-1-epa-gridded-methane-emissions/odiac-ffco2-monthgrid-v2022_User_Notebook.html#querying-the-stac-api",
    "href": "interactive-session-1-epa-gridded-methane-emissions/odiac-ffco2-monthgrid-v2022_User_Notebook.html#querying-the-stac-api",
    "title": "ODIAC Fossil Fuel CO‚ÇÇ Emissions",
    "section": "Querying the STAC API",
    "text": "Querying the STAC API\n\nimport requests\nfrom folium import Map, TileLayer\nfrom pystac_client import Client\n\n\n# Provide STAC and RASTER API endpoints\nSTAC_API_URL = \"http://ghg.center/api/stac\"\nRASTER_API_URL = \"https://ghg.center/api/raster\"\n\n#Please use the collection name similar to the one used in STAC collection.\n# Name of the collection for ODIAC dataset. \ncollection_name = \"odiac-ffco2-monthgrid-v2022\"\n\n\n# Fetching the collection from STAC collections using appropriate endpoint.\ncollection = requests.get(f\"{STAC_API_URL}/collections/{collection_name}\").json()\ncollection\n\n{'id': 'odiac-ffco2-monthgrid-v2022',\n 'type': 'Collection',\n 'links': [{'rel': 'items',\n   'type': 'application/geo+json',\n   'href': 'https://ghg.center/api/stac/collections/odiac-ffco2-monthgrid-v2022/items'},\n  {'rel': 'parent',\n   'type': 'application/json',\n   'href': 'https://ghg.center/api/stac/'},\n  {'rel': 'root',\n   'type': 'application/json',\n   'href': 'https://ghg.center/api/stac/'},\n  {'rel': 'self',\n   'type': 'application/json',\n   'href': 'https://ghg.center/api/stac/collections/odiac-ffco2-monthgrid-v2022'}],\n 'title': 'ODIAC Fossil Fuel CO‚ÇÇ Emissions',\n 'assets': None,\n 'extent': {'spatial': {'bbox': [[-180, -90, 180, 90]]},\n  'temporal': {'interval': [['2000-01-01T00:00:00+00:00',\n     '2021-12-31T00:00:00+00:00']]}},\n 'license': 'CC-BY-4.0',\n 'keywords': None,\n 'providers': [{'url': 'https://www.nies.go.jp',\n   'name': 'National Institute for Environmental Studies',\n   'roles': ['producer', 'licensor'],\n   'description': None}],\n 'summaries': {'datetime': ['2000-01-01T00:00:00Z', '2021-12-31T00:00:00Z']},\n 'description': 'The Open-Data Inventory for Anthropogenic Carbon dioxide (ODIAC) is a high-spatial resolution global emission data product of CO‚ÇÇ emissions from fossil fuel combustion (Oda and Maksyutov, 2011). ODIAC pioneered the combined use of space-based nighttime light data and individual power plant emission/location profiles to estimate the global spatial extent of fossil fuel CO‚ÇÇ emissions. With the innovative emission modeling approach, ODIAC achieved the fine picture of global fossil fuel CO‚ÇÇ emissions at a 1x1km.',\n 'item_assets': {'co2-emissions': {'type': 'image/tiff; application=geotiff; profile=cloud-optimized',\n   'roles': ['data', 'layer'],\n   'title': 'Fossil Fuel CO‚ÇÇ Emissions',\n   'description': 'CO‚ÇÇ emissions from fossil fuel combustion, cement production and gas flaring.'}},\n 'stac_version': '1.0.0',\n 'stac_extensions': None,\n 'dashboard:is_periodic': True,\n 'dashboard:time_density': 'month'}\n\n\nExamining the contents of our collection under summaries we see that the data is available from January 2000 to December 2021. By looking at the dashboard:time density we observe that the periodic frequency of these observations is monthly.\n\ndef get_item_count(collection_id):\n    count = 0\n    items_url = f\"{STAC_API_URL}/collections/{collection_id}/items\"\n\n    while True:\n        response = requests.get(items_url)\n\n        if not response.ok:\n            print(\"error getting items\")\n            exit()\n\n        stac = response.json()\n        count += int(stac[\"context\"].get(\"returned\", 0))\n        next = [link for link in stac[\"links\"] if link[\"rel\"] == \"next\"]\n\n        if not next:\n            break\n        items_url = next[0][\"href\"]\n\n    return count\n\n\n# Check total number of items available\nnumber_of_items = get_item_count(collection_name)\nitems = requests.get(f\"{STAC_API_URL}/collections/{collection_name}/items?limit={number_of_items}\").json()[\"features\"]\nprint(f\"Found {len(items)} items\")\n\nFound 264 items\n\n\n\nitems[0]\n\n{'id': 'odiac-ffco2-monthgrid-v2022-202112',\n 'bbox': [-180.0, -90.0, 180.0, 90.0],\n 'type': 'Feature',\n 'links': [{'rel': 'collection',\n   'type': 'application/json',\n   'href': 'https://ghg.center/api/stac/collections/odiac-ffco2-monthgrid-v2022'},\n  {'rel': 'parent',\n   'type': 'application/json',\n   'href': 'https://ghg.center/api/stac/collections/odiac-ffco2-monthgrid-v2022'},\n  {'rel': 'root',\n   'type': 'application/json',\n   'href': 'https://ghg.center/api/stac/'},\n  {'rel': 'self',\n   'type': 'application/geo+json',\n   'href': 'https://ghg.center/api/stac/collections/odiac-ffco2-monthgrid-v2022/items/odiac-ffco2-monthgrid-v2022-202112'}],\n 'assets': {'co2-emissions': {'href': 's3://ghgc-data-store/odiac-ffco2-monthgrid-v2022/odiac2022_1km_excl_intl_202112.tif',\n   'type': 'image/tiff; application=geotiff; profile=cloud-optimized',\n   'roles': ['data', 'layer'],\n   'title': 'Fossil Fuel CO‚ÇÇ Emissions',\n   'proj:bbox': [-180.0, -90.0, 180.0, 90.0],\n   'proj:epsg': 4326.0,\n   'proj:shape': [21600.0, 43200.0],\n   'description': 'CO‚ÇÇ emissions from fossil fuel combustion, cement production and gas flaring.',\n   'raster:bands': [{'scale': 1.0,\n     'nodata': -9999.0,\n     'offset': 0.0,\n     'sampling': 'area',\n     'data_type': 'float32',\n     'histogram': {'max': 2497.01904296875,\n      'min': -138.71914672851562,\n      'count': 11.0,\n      'buckets': [523457.0, 691.0, 95.0, 28.0, 11.0, 2.0, 2.0, 1.0, 0.0, 1.0]},\n     'statistics': {'mean': 0.9804128408432007,\n      'stddev': 14.766693454324674,\n      'maximum': 2497.01904296875,\n      'minimum': -138.71914672851562,\n      'valid_percent': 100.0}}],\n   'proj:geometry': {'type': 'Polygon',\n    'coordinates': [[[-180.0, -90.0],\n      [180.0, -90.0],\n      [180.0, 90.0],\n      [-180.0, 90.0],\n      [-180.0, -90.0]]]},\n   'proj:projjson': {'id': {'code': 4326.0, 'authority': 'EPSG'},\n    'name': 'WGS 84',\n    'type': 'GeographicCRS',\n    'datum': {'name': 'World Geodetic System 1984',\n     'type': 'GeodeticReferenceFrame',\n     'ellipsoid': {'name': 'WGS 84',\n      'semi_major_axis': 6378137.0,\n      'inverse_flattening': 298.257223563}},\n    '$schema': 'https://proj.org/schemas/v0.4/projjson.schema.json',\n    'coordinate_system': {'axis': [{'name': 'Geodetic latitude',\n       'unit': 'degree',\n       'direction': 'north',\n       'abbreviation': 'Lat'},\n      {'name': 'Geodetic longitude',\n       'unit': 'degree',\n       'direction': 'east',\n       'abbreviation': 'Lon'}],\n     'subtype': 'ellipsoidal'}},\n   'proj:transform': [0.008333333333333333,\n    0.0,\n    -180.0,\n    0.0,\n    -0.008333333333333333,\n    90.0,\n    0.0,\n    0.0,\n    1.0]}},\n 'geometry': {'type': 'Polygon',\n  'coordinates': [[[-180, -90],\n    [180, -90],\n    [180, 90],\n    [-180, 90],\n    [-180, -90]]]},\n 'collection': 'odiac-ffco2-monthgrid-v2022',\n 'properties': {'end_datetime': '2021-12-31T00:00:00+00:00',\n  'start_datetime': '2021-12-01T00:00:00+00:00'},\n 'stac_version': '1.0.0',\n 'stac_extensions': []}\n\n\nThis makes sense as there are 22 years between 2000 - 2021, with 12 months per year, meaning 264 records in total.\nBelow, we are entering the minimum and maximum values to provide our upper and lower bounds in rescale_values."
  },
  {
    "objectID": "interactive-session-1-epa-gridded-methane-emissions/odiac-ffco2-monthgrid-v2022_User_Notebook.html#exploring-changes-in-carbon-dioxide-co‚ÇÇ-levels-using-the-raster-api",
    "href": "interactive-session-1-epa-gridded-methane-emissions/odiac-ffco2-monthgrid-v2022_User_Notebook.html#exploring-changes-in-carbon-dioxide-co‚ÇÇ-levels-using-the-raster-api",
    "title": "ODIAC Fossil Fuel CO‚ÇÇ Emissions",
    "section": "Exploring Changes in Carbon Dioxide (CO‚ÇÇ) levels using the Raster API",
    "text": "Exploring Changes in Carbon Dioxide (CO‚ÇÇ) levels using the Raster API\nWe will explore changes in fossil fuel emissions in urban egions. In this notebook, we‚Äôll explore the impacts of these emissions and explore these changes over time. We‚Äôll then visualize the outputs on a map using folium.\n\n# to access the year value from each item more easily, this will let us query more explicity by year and month (e.g., 2020-02)\nitems = {item[\"properties\"][\"start_datetime\"][:7]: item for item in items} \nasset_name = \"co2-emissions\"\n\n\nrescale_values = {\"max\":items[list(items.keys())[0]][\"assets\"][asset_name][\"raster:bands\"][0][\"histogram\"][\"max\"], \"min\":items[list(items.keys())[0]][\"assets\"][asset_name][\"raster:bands\"][0][\"histogram\"][\"min\"]}\n\nNow we will pass the item id, collection name, and rescaling_factor to the Raster API endpoint. We will do this twice, once for January 2020 and again for January 2000, so that we can visualize each event independently.\n\ncolor_map = \"rainbow\" # please select the color ramp from matplotlib library.\njanuary_2020_tile = requests.get(\n    f\"{RASTER_API_URL}/stac/tilejson.json?collection={items['2020-01']['collection']}&item={items['2020-01']['id']}\"\n    f\"&assets={asset_name}\"\n    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n    f\"&rescale={rescale_values['min']},{rescale_values['max']}\", \n).json()\njanuary_2020_tile\n\n{'tilejson': '2.2.0',\n 'version': '1.0.0',\n 'scheme': 'xyz',\n 'tiles': ['https://ghg.center/api/raster/stac/tiles/WebMercatorQuad/{z}/{x}/{y}@1x?collection=odiac-ffco2-monthgrid-v2022&item=odiac-ffco2-monthgrid-v2022-202001&assets=co2-emissions&color_formula=gamma+r+1.05&colormap_name=rainbow&rescale=-138.71914672851562%2C2497.01904296875'],\n 'minzoom': 0,\n 'maxzoom': 24,\n 'bounds': [-180.0, -90.0, 180.0, 90.0],\n 'center': [0.0, 0.0, 0]}\n\n\n\njanuary_2000_tile = requests.get(\n    f\"{RASTER_API_URL}/stac/tilejson.json?collection={items['2000-01']['collection']}&item={items['2000-01']['id']}\"\n    f\"&assets={asset_name}\"\n    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n    f\"&rescale={rescale_values['min']},{rescale_values['max']}\", \n).json()\njanuary_2000_tile\n\n{'tilejson': '2.2.0',\n 'version': '1.0.0',\n 'scheme': 'xyz',\n 'tiles': ['https://ghg.center/api/raster/stac/tiles/WebMercatorQuad/{z}/{x}/{y}@1x?collection=odiac-ffco2-monthgrid-v2022&item=odiac-ffco2-monthgrid-v2022-200001&assets=co2-emissions&color_formula=gamma+r+1.05&colormap_name=rainbow&rescale=-138.71914672851562%2C2497.01904296875'],\n 'minzoom': 0,\n 'maxzoom': 24,\n 'bounds': [-180.0, -90.0, 180.0, 90.0],\n 'center': [0.0, 0.0, 0]}"
  },
  {
    "objectID": "interactive-session-1-epa-gridded-methane-emissions/odiac-ffco2-monthgrid-v2022_User_Notebook.html#visualizing-co‚ÇÇ-emissions",
    "href": "interactive-session-1-epa-gridded-methane-emissions/odiac-ffco2-monthgrid-v2022_User_Notebook.html#visualizing-co‚ÇÇ-emissions",
    "title": "ODIAC Fossil Fuel CO‚ÇÇ Emissions",
    "section": "Visualizing CO‚ÇÇ emissions",
    "text": "Visualizing CO‚ÇÇ emissions\n\n# We'll import folium to map and folium.plugins to allow mapping side-by-side\nimport folium\nimport folium.plugins\n\n# Set initial zoom and center of map for CO‚ÇÇ Layer\nmap_ = folium.plugins.DualMap(location=(34, -118), zoom_start=6)\n\n# December 2001\nmap_layer_2020 = TileLayer(\n    tiles=january_2020_tile[\"tiles\"][0],\n    attr=\"GHG\",\n    opacity=0.8,\n)\nmap_layer_2020.add_to(map_.m1)\n\n# December 2021\nmap_layer_2000 = TileLayer(\n    tiles=january_2000_tile[\"tiles\"][0],\n    attr=\"GHG\",\n    opacity=0.8,\n)\nmap_layer_2000.add_to(map_.m2)\n\n# visualising the map\nmap_\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "interactive-session-1-epa-gridded-methane-emissions/odiac-ffco2-monthgrid-v2022_User_Notebook.html#section",
    "href": "interactive-session-1-epa-gridded-methane-emissions/odiac-ffco2-monthgrid-v2022_User_Notebook.html#section",
    "title": "ODIAC Fossil Fuel CO‚ÇÇ Emissions",
    "section": "",
    "text": "# Texas, USA\ntexas_aoi = {\n    \"type\": \"Feature\",\n    \"properties\": {},\n    \"geometry\": {\n        \"coordinates\": [\n            [\n                # [13.686159004559698, -21.700046934333145],\n                # [13.686159004559698, -23.241974326585833],\n                # [14.753560168039911, -23.241974326585833],\n                # [14.753560168039911, -21.700046934333145],\n                # [13.686159004559698, -21.700046934333145],\n                [-95, 29],\n                [-95, 33],\n                [-104, 33],\n                [-104,29],\n                [-95, 29]\n            ]\n        ],\n        \"type\": \"Polygon\",\n    },\n}\n\n\n# We'll plug in the coordinates for a location\n# central to the study area and a reasonable zoom level\n\nimport folium\n\naoi_map = Map(\n    tiles=\"OpenStreetMap\",\n    location=[\n        30,-100\n    ],\n    zoom_start=6,\n)\n\nfolium.GeoJson(texas_aoi, name=\"Texas, USA\").add_to(aoi_map)\naoi_map\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n# Check total number of items available\nitems = requests.get(\n    f\"{STAC_API_URL}/collections/{collection_name}/items?limit=300\"\n).json()[\"features\"]\nprint(f\"Found {len(items)} items\")\n\nFound 264 items\n\n\n\n# Explore one item to see what it contains\nitems[0]\n\n{'id': 'odiac-ffco2-monthgrid-v2022-202112',\n 'bbox': [-180.0, -90.0, 180.0, 90.0],\n 'type': 'Feature',\n 'links': [{'rel': 'collection',\n   'type': 'application/json',\n   'href': 'https://ghg.center/api/stac/collections/odiac-ffco2-monthgrid-v2022'},\n  {'rel': 'parent',\n   'type': 'application/json',\n   'href': 'https://ghg.center/api/stac/collections/odiac-ffco2-monthgrid-v2022'},\n  {'rel': 'root',\n   'type': 'application/json',\n   'href': 'https://ghg.center/api/stac/'},\n  {'rel': 'self',\n   'type': 'application/geo+json',\n   'href': 'https://ghg.center/api/stac/collections/odiac-ffco2-monthgrid-v2022/items/odiac-ffco2-monthgrid-v2022-202112'}],\n 'assets': {'co2-emissions': {'href': 's3://ghgc-data-store/odiac-ffco2-monthgrid-v2022/odiac2022_1km_excl_intl_202112.tif',\n   'type': 'image/tiff; application=geotiff; profile=cloud-optimized',\n   'roles': ['data', 'layer'],\n   'title': 'Fossil Fuel CO‚ÇÇ Emissions',\n   'proj:bbox': [-180.0, -90.0, 180.0, 90.0],\n   'proj:epsg': 4326.0,\n   'proj:shape': [21600.0, 43200.0],\n   'description': 'CO‚ÇÇ emissions from fossil fuel combustion, cement production and gas flaring.',\n   'raster:bands': [{'scale': 1.0,\n     'nodata': -9999.0,\n     'offset': 0.0,\n     'sampling': 'area',\n     'data_type': 'float32',\n     'histogram': {'max': 2497.01904296875,\n      'min': -138.71914672851562,\n      'count': 11.0,\n      'buckets': [523457.0, 691.0, 95.0, 28.0, 11.0, 2.0, 2.0, 1.0, 0.0, 1.0]},\n     'statistics': {'mean': 0.9804128408432007,\n      'stddev': 14.766693454324674,\n      'maximum': 2497.01904296875,\n      'minimum': -138.71914672851562,\n      'valid_percent': 100.0}}],\n   'proj:geometry': {'type': 'Polygon',\n    'coordinates': [[[-180.0, -90.0],\n      [180.0, -90.0],\n      [180.0, 90.0],\n      [-180.0, 90.0],\n      [-180.0, -90.0]]]},\n   'proj:projjson': {'id': {'code': 4326.0, 'authority': 'EPSG'},\n    'name': 'WGS 84',\n    'type': 'GeographicCRS',\n    'datum': {'name': 'World Geodetic System 1984',\n     'type': 'GeodeticReferenceFrame',\n     'ellipsoid': {'name': 'WGS 84',\n      'semi_major_axis': 6378137.0,\n      'inverse_flattening': 298.257223563}},\n    '$schema': 'https://proj.org/schemas/v0.4/projjson.schema.json',\n    'coordinate_system': {'axis': [{'name': 'Geodetic latitude',\n       'unit': 'degree',\n       'direction': 'north',\n       'abbreviation': 'Lat'},\n      {'name': 'Geodetic longitude',\n       'unit': 'degree',\n       'direction': 'east',\n       'abbreviation': 'Lon'}],\n     'subtype': 'ellipsoidal'}},\n   'proj:transform': [0.008333333333333333,\n    0.0,\n    -180.0,\n    0.0,\n    -0.008333333333333333,\n    90.0,\n    0.0,\n    0.0,\n    1.0]}},\n 'geometry': {'type': 'Polygon',\n  'coordinates': [[[-180, -90],\n    [180, -90],\n    [180, 90],\n    [-180, 90],\n    [-180, -90]]]},\n 'collection': 'odiac-ffco2-monthgrid-v2022',\n 'properties': {'end_datetime': '2021-12-31T00:00:00+00:00',\n  'start_datetime': '2021-12-01T00:00:00+00:00'},\n 'stac_version': '1.0.0',\n 'stac_extensions': []}\n\n\n\n# the bounding box should be passed to the geojson param as a geojson Feature or FeatureCollection\ndef generate_stats(item, geojson):\n    result = requests.post(\n        f\"{RASTER_API_URL}/cog/statistics\",\n        params={\"url\": item[\"assets\"][asset_name][\"href\"]},\n        json=geojson,\n    ).json()\n    return {\n        **result[\"properties\"],\n        \"start_datetime\": item[\"properties\"][\"start_datetime\"][:7],\n    }\n\nWith the function above we can generate the statistics for the AOI.\n\n%%time\nstats = [generate_stats(item, texas_aoi) for item in items]\n\nCPU times: user 6.98 s, sys: 866 ms, total: 7.85 s\nWall time: 5min 49s\n\n\n\nstats[0]\n\n{'statistics': {'b1': {'min': 0.0,\n   'max': 404594.21875,\n   'mean': 12.983534915123457,\n   'count': 518400.0,\n   'sum': 6730664.5,\n   'std': 1073.4786364468523,\n   'median': 0.0,\n   'majority': 0.0,\n   'minority': 0.7153176665306091,\n   'unique': 160223.0,\n   'histogram': [[518384.0, 9.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n    [0.0,\n     40459.421875,\n     80918.84375,\n     121378.265625,\n     161837.6875,\n     202297.109375,\n     242756.53125,\n     283215.9375,\n     323675.375,\n     364134.8125,\n     404594.21875]],\n   'valid_percent': 100.0,\n   'masked_pixels': 0.0,\n   'valid_pixels': 518400.0,\n   'percentile_2': 0.0,\n   'percentile_98': 120.91593933105469}},\n 'start_datetime': '2021-12'}\n\n\n\nimport pandas as pd\n\n\ndef clean_stats(stats_json) -&gt; pd.DataFrame:\n    df = pd.json_normalize(stats_json)\n    df.columns = [col.replace(\"statistics.b1.\", \"\") for col in df.columns]\n    df[\"date\"] = pd.to_datetime(df[\"start_datetime\"])\n    return df\n\n\ndf = clean_stats(stats)\ndf.head(5)\n\n\n\n\n\n\n\n\nstart_datetime\nmin\nmax\nmean\ncount\nsum\nstd\nmedian\nmajority\nminority\nunique\nhistogram\nvalid_percent\nmasked_pixels\nvalid_pixels\npercentile_2\npercentile_98\ndate\n\n\n\n\n0\n2021-12\n0.0\n404594.21875\n12.983535\n518400.0\n6730664.5\n1073.478636\n0.0\n0.0\n0.715318\n160223.0\n[[518384.0, 9.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0,...\n100.0\n0.0\n518400.0\n0.0\n120.915939\n2021-12-01\n\n\n1\n2021-11\n0.0\n379500.71875\n12.181822\n518400.0\n6315056.5\n1006.900541\n0.0\n0.0\n0.671284\n160209.0\n[[518384.0, 9.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0,...\n100.0\n0.0\n518400.0\n0.0\n113.472582\n2021-11-01\n\n\n2\n2021-10\n0.0\n365564.12500\n11.742121\n518400.0\n6087115.5\n969.924733\n0.0\n0.0\n0.647386\n160210.0\n[[518384.0, 9.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0,...\n100.0\n0.0\n518400.0\n0.0\n109.432922\n2021-10-01\n\n\n3\n2021-09\n0.0\n369532.53125\n11.863683\n518400.0\n6150133.5\n980.453000\n0.0\n0.0\n0.653934\n160213.0\n[[518384.0, 9.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0,...\n100.0\n0.0\n518400.0\n0.0\n110.523390\n2021-09-01\n\n\n4\n2021-08\n0.0\n412252.34375\n13.224326\n518400.0\n6855490.5\n1093.796870\n0.0\n0.0\n0.728647\n160224.0\n[[518384.0, 9.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0,...\n100.0\n0.0\n518400.0\n0.0\n123.059172\n2021-08-01"
  },
  {
    "objectID": "interactive-session-1-epa-gridded-methane-emissions/odiac-ffco2-monthgrid-v2022_User_Notebook.html#visualizing-the-data-as-a-time-series",
    "href": "interactive-session-1-epa-gridded-methane-emissions/odiac-ffco2-monthgrid-v2022_User_Notebook.html#visualizing-the-data-as-a-time-series",
    "title": "ODIAC Fossil Fuel CO‚ÇÇ Emissions",
    "section": "Visualizing the Data as a Time Series",
    "text": "Visualizing the Data as a Time Series\nWe can now explore the ODIAC fossil fuel emission time series available (January 2000 -December 2021) for the Texas, Dallas area of USA. We can plot the data set using the code below:\n\nimport matplotlib.pyplot as plt\n\nfig = plt.figure(figsize=(20, 10))\n\n\nplt.plot(\n    df[\"date\"],\n    df[\"max\"],\n    color=\"red\",\n    linestyle=\"-\",\n    linewidth=0.5,\n    label=\"Max monthly CO‚ÇÇ emissions\",\n)\n\nplt.legend()\nplt.xlabel(\"Years\")\nplt.ylabel(\"CO2 emissions gC/m2/d\")\nplt.title(\"CO2 emission Values for Texas, Dallas (2000-2021)\")\n\nText(0.5, 1.0, 'CO2 emission Values for Texas, Dallas (2000-2021)')\n\n\n\n\n\n\nprint(items[2][\"properties\"][\"start_datetime\"])\n\n2021-10-01T00:00:00+00:00\n\n\n\noctober_tile = requests.get(\n    f\"{RASTER_API_URL}/stac/tilejson.json?collection={items[2]['collection']}&item={items[2]['id']}\"\n    f\"&assets={asset_name}\"\n    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n    f\"&rescale={rescale_values['min']},{rescale_values['max']}\",\n).json()\noctober_tile\n\n{'tilejson': '2.2.0',\n 'version': '1.0.0',\n 'scheme': 'xyz',\n 'tiles': ['https://ghg.center/api/raster/stac/tiles/WebMercatorQuad/{z}/{x}/{y}@1x?collection=odiac-ffco2-monthgrid-v2022&item=odiac-ffco2-monthgrid-v2022-202110&assets=co2-emissions&color_formula=gamma+r+1.05&colormap_name=rainbow&rescale=-138.71914672851562%2C2497.01904296875'],\n 'minzoom': 0,\n 'maxzoom': 24,\n 'bounds': [-180.0, -90.0, 180.0, 90.0],\n 'center': [0.0, 0.0, 0]}\n\n\n\n# Use bbox initial zoom and map\n# Set up a map located w/in event bounds\nimport folium\n\naoi_map_bbox = Map(\n    tiles=\"OpenStreetMap\",\n    location=[\n        30,-100\n    ],\n    zoom_start=8,\n)\n\nmap_layer = TileLayer(\n    tiles=october_tile[\"tiles\"][0],\n    attr=\"GHG\", opacity = 0.5\n)\n\nmap_layer.add_to(aoi_map_bbox)\n\naoi_map_bbox\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "interactive-session-1-epa-gridded-methane-emissions/odiac-ffco2-monthgrid-v2022_User_Notebook.html#summary",
    "href": "interactive-session-1-epa-gridded-methane-emissions/odiac-ffco2-monthgrid-v2022_User_Notebook.html#summary",
    "title": "ODIAC Fossil Fuel CO‚ÇÇ Emissions",
    "section": "Summary",
    "text": "Summary\nIn this notebook we have successfully explored, analysed and visualized STAC collecetion for ODIAC C02 fossisl fuel emission (2022)."
  },
  {
    "objectID": "interactive-session-3-large-point-source-methane-emission-events/index.html",
    "href": "interactive-session-3-large-point-source-methane-emission-events/index.html",
    "title": "Identifying and quantifying emissions from large point source methane emission events leveraging aircraft and satellite data",
    "section": "",
    "text": "Identifying and quantifying emissions from large point source methane emission events leveraging aircraft and satellite data"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Utilizing Open Science Techniques for Exploring Greenhouse Gas Data",
    "section": "",
    "text": "üìÖ Jan 28, 2024, üï£ 8:00 AM - 3:45 PM EST, üìç Baltimore Convention Center\nüîó Session on the AMS Website"
  },
  {
    "objectID": "index.html#description",
    "href": "index.html#description",
    "title": "Utilizing Open Science Techniques for Exploring Greenhouse Gas Data",
    "section": "Description",
    "text": "Description\nThis workshop provides a hands-on learning experience for researchers, educators, and students who are eager to harness NASA‚Äôs key greenhouse gas datasets, open-source tools, and accessible computing resources for visualizing, exploring, publishing, and communicating scientific results. Participants will learn about and utilize the new U.S. Greenhouse Gas Center (GHG Center) to examine curated, trusted data in a cloud computing environment. The activities will center around data and information aligned with three science use cases to ensure broad applicability. Participants will learn to access analysis workflows using cloud-optimized data, access data products via a standards-based catalog, configure data products for web-based visualizations, and communicate scientific discoveries through a web dashboard.\nThe workshop will provide an overview of the newly released U.S. Greenhouse Gas Center, a prototype system that aims to integrate federal and non-federal data, reflecting transparency in both data and methods, to address a variety of end user needs for greenhouse gas monitoring and to bring together actionable information from multiple sources. Examples of products that will be part of this training include methane concentration anomalies from space-based instruments (e.g., EMIT), data on natural emissions and fluxes available from the U.S. GHG Center, as well as gridding processes of anthropogenic methane emissions."
  },
  {
    "objectID": "index.html#learning-outcomes",
    "href": "index.html#learning-outcomes",
    "title": "Utilizing Open Science Techniques for Exploring Greenhouse Gas Data",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\nUpon completing this workshop, participants will be able to:\n\nUnderstand the scientific basis of the GHG products from the newly formed U.S. Greenhouse Gas Center.\nEmploy Python and Jupyter Notebooks for effective data analysis and visualization of Earth science data in the cloud.\nDisseminate and share scientific findings to achieve a wider impact.\nUnderstand basic principles for contributing to open-sourced software projects."
  },
  {
    "objectID": "index.html#target-audience",
    "href": "index.html#target-audience",
    "title": "Utilizing Open Science Techniques for Exploring Greenhouse Gas Data",
    "section": "Target Audience",
    "text": "Target Audience\nThe target audience for this workshop includes Earth Science researchers, educators, and students across all career stages and disciplines who are interested in utilizing GHG datasets and open-source tools for their research projects. The workshop will be beneficial for both experienced programmers seeking an overview of modern open tools and those just getting started with scientific programming."
  },
  {
    "objectID": "index.html#code-of-conduct",
    "href": "index.html#code-of-conduct",
    "title": "Utilizing Open Science Techniques for Exploring Greenhouse Gas Data",
    "section": "Code of Conduct",
    "text": "Code of Conduct\nThis workshop will be held following the Transform to Open Science Code of Conduct."
  }
]